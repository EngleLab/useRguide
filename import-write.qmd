# Import Data {#sec-import-data}

```{r}
#| results: "asis"
#| echo: false

source("_common.R")
```

Every R script that you write will require you to import (read in) a data file and output (write) a new data file.

In this Chapter you will learn various functions to import and output comma-separate value (csv), tab-delimited, SPSS, E-Prime -Export data files, and a batch of multiple data files.

For most of these data types we can use the [**readr** package](https://readr.tidyverse.org){target="_blank"}

```{r}
#| label: fig-readr-logo
#| echo: false
#| out-width: 25%
#| fig-align: left
#| fig-cap: readr logo

knitr::include_graphics(rep("images/readr_logo.png"))
```

The `readr` package contains useful functions for importing and outputting data files.

Go ahead and install the `readr` package. In the console type:

```{r}
#| eval: false

install.packages("readr")
```

We will also use the `foreign` and `haven` packages for SPSS data files

```{r}
#| eval: false

install.packages("foreign")
install.packages("haven")
```

We will use some example data files for this chapter. Go ahead and download these files. You will have to unzip the file. For now just unzip it in your **downloads folder**. Inside the unzipped folder you will see a number of data files in different file formats.

::: callout-tip
[Download example data files](http://englelab.gatech.edu/useRguide/Import_example.zip)
:::

## CSV Files {#sec-csv-files}

`csv` files are by far the easiest files to import into R and most software programs. For this reason, I suggest any time you want to save/output a data file to your computer, do it in `csv` format.

### Import .csv

We can import `csv` files using `read_csv()` from the `readr` package.

```{r}
#| eval: false

library(readr)
read_csv("filepath/datafile.csv")
```

You can see this is very simple. We just need to specify a file path to the data.

::: callout-important
DO NOT USE ABSOLUTE FILE PATHS!
:::

I will talk more about file paths later but for now we will use `absolute` file paths, although it is highly suggested not to use them. This chapter is more about the different functions to import various types of data files.

First, figure out the `absolute` file path to your downloads folder (or wherever the unzipped data folder is located). On Windows the `absolute` file path will usually start from the `C:/` drive. On Macs, it starts from `~/`

Import the `Flanker_Scores.csv` file. You might have something that looks like

```{r}
#| eval: false

read_csv("~/Downloads/Flanker_Scores.csv")
```

However, this just printed the output of `read_csv()` to the console. To actually import this file into R, we need to assign it to an object in our `Environment`.

```{r}
#| eval: false

import_csv <- read_csv("~/Downloads/Flanker_Scores.csv")
```

You can name the object whatever you like. I named it `import_csv`.

To view the data frame

```{r}
#| eval: false

View(import_csv)
```

### Output .csv

We can output a `csv` file using `write_csv()` from the `readr` package.

```{r}
#| eval: false

write_csv(object, "filepath/filename.csv")
```

Let's output the object `import_csv` to a `csv` file named: `new_Flanker_Scores.csv` to the downloads folder

```{r}
#| eval: false

write_csv(import_csv, "~/Downloads/new_Flanker_Scores.csv")
```

Note that whenever writing (outputting) a file to our computer there is no need to assign the output to an object.

## Tab-Delimited {#sec-tab-delimited}

`tab-delimited` files are a little more tedious to import just because they require specifying more arguments. Which means you have to memorize more to import `tab-delimited` files.

### Import .txt

To import a `tab-delimited` file we can use `read_delim()` from the `readr` package.

```{r}
#| eval: false

read_delim("filepath/filename.txt", delim = "\t", 
           escape_double = FALSE, trim_ws = TRUE)
```

There are three additional arguments we have to specify: `delim`, `escape_double`, and `trim_ws`. The notation for `tab-delimted` files is `"\t"`.

Let's import the `Flanker_raw.txt` file

```{r}
#| eval: false

import_tab <- read_delim("~/Downloads/Flanker_raw.txt", "\t", 
                         escape_double = FALSE, trim_ws = TRUE)
```

View the `import_tab` object

### Output .txt

We can output a `tab-delimited` file using `write_delim()` from the `readr` package.

```{r}
#| eval: false

write_delim(object, 
            path = "filepath/filename.txt", delim = "\t")
```

Output the `import_tab` object to a file named: `new_Flanker_raw.txt`

```{r}
#| eval: false

write_delim(import_tab, 
            path = "~/Downloads/Flanker_raw.txt", delim = "\t")
```

## SPSS {#sec-spss}

As horrible as it might sound, there might be occasions where we need to import an SPSS data file. And worse, we might need to output an SPSS data file!

I will suggest to use different packages for importing and outputing spss files.

### Import .sav

To import an SPSS data file we can use `read.spss()` from the `foreign` package.

```{r}
#| eval: false

library(foreign)
read.spss("filepath/filename.sav", 
          to.data.frame = TRUE, use.value.labels = TRUE)
```

The `use.value.labels` argument allows us to import the value labels from an SPSS file.

Import and View the `sav` file `CH9 Salary Ex04.sav`

```{r}
#| eval: false

import_sav <- read.spss("~/Downloads/CH9 Salary Ex04.sav")
```

### Output .sav

To output an SPSS data file we can use `write_sav()` from the `haven` packge.

```{r}
#| eval: false

library(haven)
write_sav(object, "filepath/filename.sav")
```

Go ahead and output the `import_sav` object to a file: `new_CH9 Salary Ex04.sav`

```{r}
#| eval: false

write_sav(import_sav, "~/Downloads/new_CH9 Salary Ex04.sav")
```

## RStudio Import GUI {#sec-rstudio-import-gui}

The nice thing about R Studio is that there is also a GUI for importing data files.

When you are having difficulty importing a file correctly or unsure of the file format you can use the RStudio Import GUI.

In the **Environment** window click on **"Import Dataset"**. You will see several options available, these options all rely on different packages. Select whatever data type you want to import

You will see a data import window open up that looks like this

```{r}
#| label: fig-rstudioGUI-import
#| echo: false
#| fig-cap: RStudio Import GUI

knitr::include_graphics(rep("images/rstudioGUI-readr.png"))
```

Select "Browse" on the top right and select the data file you want to import.

The "Data Preview" window will let you see if it is importing it in the right format. You can change the import options below this.

You might want to change the "Name" but you can always do this later in the R Script.

Make sure all the settings are correct by assessing the "Data Preview" window. Does the data frame look as you would expect it to?

Finally, copy and paste the code you need in the "Code Preview" box at the bottom right. You might not always need the `library(readr)` or `View(data)` lines.

Rather than selecting "Import" I suggest just closing out of the window and pasting the code into your R script.

`csv` files have a nice feature in that RStudio knows that these are file types we might want to import. So instead of navigating through the `Import Dataset` GUI we can just click on the file in the `Files` window pane.

## E-Prime -Export {#sec-e-prime--export}

The E-Prime program we use to administer tasks has the option to output a .txt file. These file types are appended with **-Export** in the filename. These files are tab delimited **but also have a unique encoding** which makes them difficult to figure out how to import into R. After some trial and error I figured out they are encoded as **UCS-2LE**, thus they can be imported with the following settings in `read_delim()`

```{r}
#| eval: false

read_delim("data/folder", delim = "\t", 
           escape_double = FALSE, trim_ws = TRUE, na = "NULL",
           locale = locale(encoding = "UCS-2LE"))
```

## Multiple Files {#sec-multiple-files}

You might find yourself in a situation where you need to import multiple data files and merge them into a single dataframe. For instance, with a batch of E-Prime -Export data files.

### Bind {#sec-multiple-files-bind}

In R, a "bind" is combining data frames together by staking either the rows or columns. It is unlikely that we you will need to do a column bind so we can skip that. A row "bind" takes data frames that have the same columns but different rows. This will happen if you have separate data files for each subject from the same task. Each subject data file will have their unique rows (subject by trial level data) but they will all have the same columns.

To bind multiple files together requires only a couple of steps

1.  Get a list of all the files

2.  Import and bind the list of files using `purrr::map_df()`

    `map_df()` is a function from the `purrr` R package that allows you to apply a function to each element of a list or vector and then combine the results into a data frame. It is especially useful when you have a list of data frames that you want to combine into a single data frame. The function applies a function to each data frame in the list, and then combines the results into a single data frame. *This paragraph was written by Notion AI*

```{r}
#| eval: false

library(readr)
library(dplyr)
library(purrr)

# 1. Get a list of all files
files <- list.files("data/folder", pattern = "-Export", 
                    full.names = TRUE)

# 2. Import and bind the list of files using purrr::map_df()
data_import <- files %>%
  map_df(read_delim, delim = "\t", 
         escape_double = FALSE, trim_ws = TRUE, na = "NULL",
         locale = locale(encoding = "UCS-2LE"))
```

This example shows how to import multiple E-Prime -Export files into a single dataframe. But the same procedure, with different arguments inside of `purrr::map_df()`, can be used for any type of data file.

### Join {#sec-multiple-files-join}

In R, a "join" is merging data frames together that have at least some rows in common (e.g. Same Subject IDs) and have at least one column that is different. The rows that are common serve as the reference for how to "join" the data frames together.

To join multiple files together requires a few steps:

1.  Get a list of all the files

2.  Import the list of files using `purrr::map_df()`

    `map_df()` is a function from the `purrr` R package that allows you to apply a function to each element of a list or vector and then combine the results into a data frame. It is especially useful when you have a list of data frames that you want to combine into a single data frame. The function applies a function to each data frame in the list, and then combines the results into a single data frame. *This paragraph was written by Notion AI*

3.  Join each imported data file into a single data frame by a unique id using `purrr::reduce()` and `dplyr::full_join()`.

    The function reduce() from the purrr R package is used to iteratively apply a function to a list or vector and accumulate the results. The function takes two arguments: the list or vector to be processed, and the function to be applied to each element. The function is applied to the first element and the result is stored. The function is then applied to the stored result and the second element, and the result is stored. This process is repeated until all elements have been processed, and the final result is returned. This can be useful for operations like calculating the sum or product of a list of numbers, or concatenating a list of strings. *This paragraph was written by Notion AI*

```{r}
#| eval: false

library(readr)
library(dplyr)
library(purrr)

# 1. Get a list of all files
files <- list.files("data/folder", pattern = "_Scores", 
                    full.names = TRUE)

# 2 - 3. Import with lapply() and then join with plyr::join_all()
data_import <- files %>%
  map(read_csv) %>%
  reduce(full_join, by = "Subject")
```

This example shows how to import multiple scored data files (csv file type) and join all of them by ids in the "Subject" column using `purrr::reduce()` and `dplyr::full_join()`.
