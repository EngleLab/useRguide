[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AWM useRguide",
    "section": "",
    "text": "Welcome\nThe useRguide for the Attention & Working Memory Lab at Georgia Tech documents the steps and tools for how we process and analyze data in our lab.\nThe workflow and data processing steps presented in this guide are specific to the type of data we tend to work with in our lab. We primarily collect behavioral data on a large set of cognitive tasks to test individual differences in cognitive ability. However, you will find that most of the principles presented here apply to working with other types of data.\nFor a more complete training in R, see the R for the Psychology Student Workshop.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installs and Updates",
    "section": "",
    "text": "Install Software",
    "crumbs": [
      "Installs and Updates"
    ]
  },
  {
    "objectID": "installation.html#install-r",
    "href": "installation.html#install-r",
    "title": "Installs and Updates",
    "section": "Install R",
    "text": "Install R\nFirst you need to download the latest version of R from their website https://www.r-project.org\n\nSelect CRAN on the left, just under Download\nSelect the first option under 0-Cloud\nSelect the download option depending on your computer\nSelect the base installation (for Windows) or the Latest Release (for Mac)\nOpen and Run the installation file",
    "crumbs": [
      "Installs and Updates"
    ]
  },
  {
    "objectID": "installation.html#install-rstudio",
    "href": "installation.html#install-rstudio",
    "title": "Installs and Updates",
    "section": "Install RStudio",
    "text": "Install RStudio\nThe easiest way to interact with R is through the RStudio environment. To do this you need to download RStudio\n\nSelect the Free version of RStudio Desktop\n\nSelect the download option depending on your computer",
    "crumbs": [
      "Installs and Updates"
    ]
  },
  {
    "objectID": "installation.html#update-r",
    "href": "installation.html#update-r",
    "title": "Installs and Updates",
    "section": "Update R",
    "text": "Update R\nIf you already have R installed, but want to update it to the most current version follow these steps.\nWarning: When updating R (not RStudio), it may remove all packages you have installed\nFirst check what version of R you have installed.\n\nOpen RStudio\nIn the console window you will see the R version you are running (e.g., R version 4.1.0)\nIf you have an R version older than 4.0.0 than you need to update R.\nRun the following lines of code in your console window. This is an easy way to re-install all your currently installed packages. This step will save a list of packages to re-install later.\n\n\n# Save current packages and their versions to object called ip\n\nip &lt;- installed.packages()\nip\n\n# Save the object as an .rds file\n\nsaveRDS(ip, \"CurrentPackages.rds\")\n\n\nExit out of all R or RStudio windows\nDownload and install the latest version of R (see the section on installing R above)\nOpen RStudio\nCheck if your previously installed packages are installed using the Packages tab in the bottom right window\nIf you need to re-install your previous packages, then run the following lines of code\n\n\n# After updating R, load the file and reinstall packages\n\nip &lt;- readRDS(\"CurrentPackages.rds\")\n\ninstall.packages(ip[,1])",
    "crumbs": [
      "Installs and Updates"
    ]
  },
  {
    "objectID": "installation.html#update-rstudio",
    "href": "installation.html#update-rstudio",
    "title": "Installs and Updates",
    "section": "Update RStudio",
    "text": "Update RStudio\nGo to Help -&gt; Check for Updates",
    "crumbs": [
      "Installs and Updates"
    ]
  },
  {
    "objectID": "installation.html#customizing-rstudio",
    "href": "installation.html#customizing-rstudio",
    "title": "Installs and Updates",
    "section": "Customizing RStudio",
    "text": "Customizing RStudio\nComing soonâ€¦",
    "crumbs": [
      "Installs and Updates"
    ]
  },
  {
    "objectID": "data-proc-overview.html",
    "href": "data-proc-overview.html",
    "title": "1Â  Overview",
    "section": "",
    "text": "How We Do Research\nWe make use of large data collection efforts where we recruit 300-500 people to participate in multiple 2-3 hour sessions and perform up to 40+ cognitive tasks. A single large data collection effort will contain multiple research projects and publications.\nFor instance, in one of our recent data collection efforts (2020-2022) we recruited 461 participants for 5 2.5-hour sessions in which they completed 42 cognitive tasks. Multiple publications have resulted from this data collection effort with several more in the works:\nBurgoyne, Seeburger, and Engle (2024) . Modality Matters: Three Auditory Conflict Tasks to Measure Individual Differences in Attention Control\nBurgoyne et al. (2023) . Nature and Measurement of Attention Control\nDraheim, Tsukahara, and Engle (2023) . Replication and Extension of the Toolbox Approach to Measuring Attention Control.\nOSF BOAT: See a description and full list of publications and projects to result from this data collection effort on OSF.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data-proc-overview.html#solution-to-challenges",
    "href": "data-proc-overview.html#solution-to-challenges",
    "title": "1Â  Overview",
    "section": "Solution to Challenges",
    "text": "Solution to Challenges\nSimply using R is not enough\n\nDocument steps and aim for full reproducibility\nKeep projects, data files, and scripts well orgainzed",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data-proc-overview.html#what-does-reproducibility-mean",
    "href": "data-proc-overview.html#what-does-reproducibility-mean",
    "title": "1Â  Overview",
    "section": "What does reproducibility mean?",
    "text": "What does reproducibility mean?\nReproducibility means that all data processing and analysis steps can be fully reproduced using only the original raw data files and the execution of the R scripts. There are different levels of reproducibility (I made these up):\n\nPartially reproducible - only some data processing and analysis steps can be reproduced, which may be due to a lack of original raw data files, the â€œjust get it doneâ€ approach, or the use of proprietary and non-reproducible software.\nMinimally reproducible (acceptable) - all data processing and analysis steps can be reproduced on any research team members computer without any modifications needed.\nModerately reproducible (desired) - meets the minimal level plus other people not involved in the research project can reproduce the steps with minimal modifications.\nHighly reproducible (good luck!) - fully reproducible without major modifications needed by people not involved in the research project 5 - 10+ years from now.\n\nA minimal level of reproducibility is still acceptable, as achieving more requires significant time and effort. We should strive for a moderate amount of reproducibility but achieving it requires more than just writing code. Your code must be organized, easy to understand, and include notes and documentation. Even if you or someone else attempts to reproduce your steps in the future, they can modify the code to make it work. The highest level of reproducibility is difficult to achieve due to software and code updates. Your code may only work with the current version of R or other packages. There are solutions to this problem of software and code updates, but who knows if those will work in the future!\n\nSimply using R for data analysis does not guarantee that your workflow is reproducible. In fact, there are many non-reproducible ways to use R. To ensure at least a moderate level of reproducibility, consider the following criteria (this is not an exhaustive list):\n\nYour statistical analysis (the final step) can be fully reproduced from the raw data files and your R scripts\nYour code can be reproduced on other computers without any modifications\nYour data and R scripts are organized and documented in a way that makes them easily understandable\n\nThis last criterion is extremely important, but is often overlooked. If others cannot understand your workflow, then it is not moderately reproducible. Therefore, it is important to take the time and think about the organization of your project, files, data, and scripts.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data-proc-overview.html#compile-raw-data",
    "href": "data-proc-overview.html#compile-raw-data",
    "title": "1Â  Overview",
    "section": "Compile Raw Data",
    "text": "Compile Raw Data\nData is collected locally on running room computers in the lab, each with individual subject files for every session and task. The data is organized by session/task on each of these computers but we need to organize the folders just by /task and to also compile the data from all the computers in one location.\nWe use a copy_to_drive.R script to compile the raw data from all the computers onto a Network Drive.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can find a template for the copy_to_drive.R script file on the Network Drive",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data-proc-overview.html#sharepoint---data-collection",
    "href": "data-proc-overview.html#sharepoint---data-collection",
    "title": "1Â  Overview",
    "section": "SharePoint - Data Collection",
    "text": "SharePoint - Data Collection\nWe use the Network Drive to transfer data files to the labâ€™s SharePoint, where the data will be permanently stored. A SharePoint/Data Collection/[Study Name] directory is where ALL the raw data files for that data collection effort are stored.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data-proc-overview.html#sharepoint---data-analysis",
    "href": "data-proc-overview.html#sharepoint---data-analysis",
    "title": "1Â  Overview",
    "section": "SharePoint - Data Analysis",
    "text": "SharePoint - Data Analysis\nRecall that a single data collection effort will contain multiple research projects, all with their own combination of tasks and decisions about processing, scoring, and cleaning the data. To maintain reproducibility across these research projects, we need to create a separate Data Analysis repository for a single data collection effort.\nOnce you create a data analysis repository in SharePoint/Data Analysis, you can copy over data files for the tasks specific to that research project. In SharePoint/Data Analysis/[Project Name] is where the data is processed, scored, cleaned, and analyzed for that research project.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "compile-raw-data.html",
    "href": "compile-raw-data.html",
    "title": "\n2Â  Compile Raw Data\n",
    "section": "",
    "text": "There are three stages of processing and analyzing data in our lab\n\n\nData Preparation: Convert messy raw data files into tidy raw data files\n\nData Scoring: Calculate aggregate scores, clean data, remove outliers, and more\n\nData Analysis: Perform statistical analysis and visualize data\n\nAll the steps in our data processing workflow can be fully reproduced with only the original raw data files and R scripts.\nBut first, we need to compile, organize, and store the raw data files.\nCompile Raw Data\nData is collected locally on running room computers in the lab. Each computer will have a different combination of data from each subject and session number. On the running room computers the data is organized by session / task\nğŸ“ Session 1\nÂ Â Â Â  ğŸ“ 1. OSpan\nÂ Â Â Â  ğŸ“ 2. RAPM\nÂ Â Â Â  ğŸ“ 3. Antisaccade\nÂ Â Â Â  ğŸ“ And so on\nğŸ“ Session 2\nğŸ“ Session 3\nğŸ“ Session 4\nIdeally, we want the data organized just by task (we also like to get rid of the number in the folder name). And each task folder to have all the data from all subjects that have participated.\nğŸ“ OSpan\nğŸ“ RAPM\nğŸ“ Antisaccade\nWe use a copy_to_drive.R script to compile the raw data from all the computers onto a Network Drive and at the same time reorgnize the data by task.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can find a template for the copy_to_drive.R script file on the Network Drive\n\n\nThe template looks something link:\nSharePoint - Data Collection\nLink to SharePoint\nWe use the Network Drive simply to transfer data files to the labâ€™s SharePoint, where the data will be permanently stored. A SharePoint/Data Collection/[Study Name] directory is where ALL the raw data files for that data collection effort are stored.\n\n\n\n\nThe organization of data files and scripts looks something like:\nğŸ“ data\nÂ Â Â Â  ğŸ“ raw (created from _raw.R scripts)\nÂ Â Â Â Â Â Â Â Â Â  ğŸ“„ OSpan_raw.csv\nÂ Â Â Â Â Â Â Â Â Â  ğŸ“„ RAPM_raw.csv\nÂ Â Â Â Â Â Â Â Â Â  ğŸ“„ Antisaccade_raw.csv\nÂ Â Â Â Â Â Â Â Â Â  ğŸ“ messy (original files created from task program)\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ğŸ“ OSpan\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ğŸ“„ OSpan_subjID.txt\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ğŸ“ RAPM\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ğŸ“ Antisaccade\nğŸ“ R\nÂ Â Â Â  ğŸ“„ OSpan_raw.R\nÂ Â Â Â  ğŸ“„ RAPM_raw.R\nÂ Â Â Â  ğŸ“„ Antisaccade_raw.R",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Compile Raw Data</span>"
    ]
  },
  {
    "objectID": "setup-project.html",
    "href": "setup-project.html",
    "title": "\n3Â  Setup Project\n",
    "section": "",
    "text": "For every data collection study there are multiple data analysis projects that result in published papers. The data analysis projects will share common tasks but might use different criteria for scoring, cleaning, and analyzing the data. Because of this, and just for organization, we need to keep data collection and data analysis projects separate.\nThe data collection repository (SharePoint / Data Collection / [Study Name]) should be where raw and tidy data files, along with some R scripts are stored.\nEach data analysis project should be created from the data files in the data collection repository.\nSetup Folders\n\nCreate a folder for your project that contains the three following folders\n\nğŸ“ analyses\nğŸ“ data\nğŸ“ R\n\nInside of the data folder create a raw/messy folder and a scored folder\n\nğŸ“ data\nÂ Â Â ğŸ“ raw\nÂ Â Â Â Â Â ğŸ“ messy\nÂ Â Â ğŸ“ scored\n\nCreate an RStudio Project in the projectâ€™s root directory\n\n\nFile -&gt; New Projectâ€¦ -&gt; Existing Directory\n\nCopy Data Files\nOnce you create a data analysis repository in SharePoint/Data Analysis, you can copy over data files for the tasks specific to that research project.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnly copy over the messy raw data files, otherwise your project will not be fully reproducible\n\n\nDownload R Script Templates\nThe englelab package contains R script templates you can download\nIn the console window, type:\n\nenglelab::get_template(raw_script = TRUE, score_script = TRUE, \n                       merge_script = TRUE, analysis_script = TRUE, \n                       wmc_scripts = TRUE, ac_scripts = TRUE, \n                       main_script = TRUE)\n\nCopy From Other Projects\nIf R scripts already exist in other projects for processing data from tasks you are using in your current project, then you can also just copy and paste those over to your project.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Setup Project</span>"
    ]
  },
  {
    "objectID": "data-prep.html",
    "href": "data-prep.html",
    "title": "\n4Â  Data Preparation\n",
    "section": "",
    "text": "Overview of Template\nYou can download an R script template to convert messy raw data files into tidy raw data files:\nenglelab::get_template(raw_script = TRUE)",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#setup",
    "href": "data-prep.html#setup",
    "title": "\n4Â  Data Preparation\n",
    "section": "Setup",
    "text": "Setup\n\n# ---- Setup ------------------\n# packages\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(purrr) # delete if not importing a batch of files\n\n# directories\nimport_dir &lt;- \"data/raw/messy\"\noutput_dir &lt;- \"data/raw\"\n\n# file names\ntask &lt;- \"taskname\"\nimport_file &lt;- paste(task, \".txt\", sep = \"\")\noutput_file &lt;- paste(task, \"raw.csv\", sep = \"_\")\n# -----------------------------\n\nThe Setup section is to:\n\nLoad any packages used in the script\nSet the directories of where to import and output data files to\nSet the file names of the data files to be imported and outputted\n\nI like to include the directory and file names at the top of the script that way it is easy to see what is being imported/outputted and from where right at the top of the script rather than having to search through the script for this information.\nWe can then use the import_dir , output_dir, import_file, and output_file variables in the script when we import and output a data file.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#import",
    "href": "data-prep.html#import",
    "title": "\n4Â  Data Preparation\n",
    "section": "Import",
    "text": "Import\nTwo different import options are included in the script:\n\n\nImport a single file: You can use the standard import functions from readr to do this\n\nImport multiple files and merge them: To do this, you need to use purrr::map_df() with a readr import function\n\n\n# ---- Import Data ------------\n# to import a single file\ndata_import &lt;- read_delim(here(import_dir, import_file), delim = \"\\t\",\n                          escape_double = FALSE, trim_ws = TRUE)\n\n# alternatively to import a batch of files...\n# change the arguments in purrr::map_df() depending on type of data files\n# this example is for files created from eprime and needs encoding = \"UCS-2LE\"\nfiles &lt;- list.files(here(import_dir, task), \n                    pattern = \".txt\", full.names = TRUE)\ndata_import &lt;- files |&gt;\n  map_df(~ read_delim(.x, locale = locale(encoding = \"UCS-2LE\"), \n                      delim = \"\\t\", escape_double = FALSE, \n                      trim_ws = TRUE, na = \"NULL\"))\n# -----------------------------",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#tidy-data",
    "href": "data-prep.html#tidy-data",
    "title": "\n4Â  Data Preparation\n",
    "section": "Tidy Data",
    "text": "Tidy Data\nThis is the meat of the script, where the action happens. It will also be different for every task, obviously. I will cover common steps in more detail below.\n\n# ---- Tidy Data --------------\ndata_raw &lt;- data_import |&gt;\n  rename() |&gt;\n  filter() |&gt;\n  mutate() |&gt;\n  select()\n# -----------------------------",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#save-data",
    "href": "data-prep.html#save-data",
    "title": "\n4Â  Data Preparation\n",
    "section": "Save Data",
    "text": "Save Data\nNo need to change anything here. Isnâ€™t that nice?\n\n# ---- Save Data --------------\nwrite_csv(data_raw, here(output_dir, output_file))\n# -----------------------------\n\nrm(list = ls())",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#combine-information-across-columns",
    "href": "data-prep.html#combine-information-across-columns",
    "title": "\n4Â  Data Preparation\n",
    "section": "Combine information across columns",
    "text": "Combine information across columns\nYou can probably guess that the data contained in slide1.resp and slide2.resp contains the same information about what response was made. But one is for practice trials and the other for real trials. This should just be combined in one column. Same thing with slide1.rt and slide2.rt.\nThere is a convenient function to do this, dplyr::coalesce()\n\n\nCode\nData Frame\n\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(TrialProc = `Proc Trial`) |&gt;\n  filter(TrialProc == \"prc\" | TrialProc == \"tsk\") |&gt;\n  mutate(Response = coalesce(slide1.resp, slide2.resp),\n         RT = coalesce(slide1.rt, slide2.rt))\n\nView the Data Frames tab to see the resulting data frames\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#values-in-columns-dont-make-sense",
    "href": "data-prep.html#values-in-columns-dont-make-sense",
    "title": "\n4Â  Data Preparation\n",
    "section": "Values in columns donâ€™t make sense",
    "text": "Values in columns donâ€™t make sense\nSome common examples\n\nThe trial number continues across practice practice and real trials\nCondition has values of 0 and 1. What do 0 and 1 mean???\nTrialProc has values that can be more clear\nValues in columns Response and Ans do not make sense. What do 1, 2, and 3 mean???\n\n\n\nCode\nData Frame\n\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(TrialProc = `Proc Trial`) |&gt;\n  filter(TrialProc == \"prc\" | TrialProc == \"tsk\") |&gt;\n  mutate(Response = coalesce(slide1.resp, slide2.resp),\n         RT = coalesce(slide1.rt, slide2.rt),\n         Condition = case_when(COND == 0 ~ \"congruent\",\n                               COND == 1 ~ \"incongruent\"),\n         TrialProc = case_when(TrialProc == \"prc\" ~ \"practice\",\n                               TrialProc == \"tsk\" ~ \"real\"),\n         Response = case_when(Response == 1 ~ \"red\",\n                              Response == 2 ~ \"green\",\n                              Response == 3 ~ \"blue\"),\n         Correct_Response = case_when(Ans == 1 ~ \"red\",\n                                      Ans == 2 ~ \"green\",\n                                      Ans == 3 ~ \"blue\")) |&gt;\nmutate(.by = c(ID, TrialProc),\n         Trial = row_number())\n\nView the Data Frame tab to see the resulting data frame\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-prep.html#add-additional-columns",
    "href": "data-prep.html#add-additional-columns",
    "title": "\n4Â  Data Preparation\n",
    "section": "Add additional columns",
    "text": "Add additional columns\nYou may have noticed that there is no column corresponding to accuracy. We have Response and Correct_Response information so we can create a new column for Accuracy\n\n\nCode\nData Frame\n\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(TrialProc = `Proc Trial`) |&gt;\n  filter(TrialProc == \"prc\" | TrialProc == \"tsk\") |&gt;\n  mutate(Response = coalesce(slide1.resp, slide2.resp),\n         RT = coalesce(slide1.rt, slide2.rt),\n         Condition = case_when(COND == 0 ~ \"congruent\",\n                               COND == 1 ~ \"incongruent\"),\n         TrialProc = case_when(TrialProc == \"prc\" ~ \"practice\",\n                               TrialProc == \"tsk\" ~ \"real\"),\n         Response = case_when(Response == 1 ~ \"red\",\n                              Response == 2 ~ \"green\",\n                              Response == 3 ~ \"blue\"),\n         Correct_Response = case_when(Ans == 1 ~ \"red\",\n                                      Ans == 2 ~ \"green\",\n                                      Ans == 3 ~ \"blue\"),\n         Accuracy = case_when(Response == Correct_Response ~ 1,\n                              Response != Correct_Response ~ 0)) |&gt;\nmutate(.by = c(ID, TrialProc),\n         Trial = row_number())\n\nView the Data Frame tab to see the resulting data frames\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "data-score.html",
    "href": "data-score.html",
    "title": "\n5Â  Data Scoring\n",
    "section": "",
    "text": "Overview of Template\nYou can download an R script template to score tidy raw data files:\nenglelab::get_template(score_script = TRUE)",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#setup",
    "href": "data-score.html#setup",
    "title": "\n5Â  Data Scoring\n",
    "section": "Setup",
    "text": "Setup\n\n# ---- Setup ------------------\n# packages\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(englelab)    # for data cleaning functions\nlibrary(tidyr)       # for pivot_wider. delete if not using\nlibrary(psych)       # for cronbach's alpha. delete if not using\n\n# directories\nimport_dir &lt;- \"data/raw\"\noutput_dir &lt;- \"data/scored\"\n\n# file names\ntask &lt;- \"taskname\"\nimport_file &lt;- paste(task, \"raw.csv\", sep = \"_\")\noutput_file &lt;- paste(task, \"Scores.csv\", sep = \"_\")\n\n## data cleaning parameters\noutlier_cutoff &lt;- 3.5\n# -----------------------------\n\nThe Setup section is to:\n\nLoad any packages used in the script\nSet the directories of where to import and output data files to\nSet the file names of the data files to be imported and outputted\nSet data cleaning parameters (e.g., outlier criterion)",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#import",
    "href": "data-score.html#import",
    "title": "\n5Â  Data Scoring\n",
    "section": "Import",
    "text": "Import\nGiven that 1) you created a tidy raw data file in .csv format, and 2) you specified import_dir and import_file in the setup section, you most likely do not need to change anything here.\nOptionally, you might want to go ahead and filter out any rows that you absolutely do not want to include at any point in scoring the data (e.g., practice trials or certain subjects).\n\n# ---- Import Data ------------\ndata_import &lt;- read_csv(here(import_dir, import_file)) |&gt;\n  filter()\n# -----------------------------",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#score-data",
    "href": "data-score.html#score-data",
    "title": "\n5Â  Data Scoring\n",
    "section": "Score Data",
    "text": "Score Data\nThe Score Data section is where most of the work needs to be done. You should be using dplyr and possibly tidyr to do most of the work here, though you may need other packages and functions. You can delete whatever is in there, that is just a placeholder as an example of the type of functions you might use.\n\n# ---- Score Data -------------\ndata_scores &lt;- data_import |&gt;\n  summarise(.by = Subject)\n# -----------------------------",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#clean-data",
    "href": "data-score.html#clean-data",
    "title": "\n5Â  Data Scoring\n",
    "section": "Clean Data",
    "text": "Clean Data\nThe next section of the script template is for cleaning the data by removing problematic subjects and/or removing outliers.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#reliability",
    "href": "data-score.html#reliability",
    "title": "\n5Â  Data Scoring\n",
    "section": "Reliability",
    "text": "Reliability\nThere are two standard ways of calculating reliability: split-half and cronbachâ€™s alpha. The script template provides some template code for calculating both of these.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#save-data",
    "href": "data-score.html#save-data",
    "title": "\n5Â  Data Scoring\n",
    "section": "Save Data",
    "text": "Save Data\nNo need to change anything here. Isnâ€™t that nice?\n\n# ---- Save Data --------------\nwrite_csv(data_raw, here(output_dir, output_file))\n# -----------------------------\n\nrm(list = ls())",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#between-subjects-anova",
    "href": "data-score.html#between-subjects-anova",
    "title": "\n5Â  Data Scoring\n",
    "section": "Between-Subjects ANOVA",
    "text": "Between-Subjects ANOVA\nCondition is not a between-subject variable in this sample data but if you have a between-subject variable or design, you will want to keep the column(s) for that variable(s) in long format.",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#within-subjects-anova",
    "href": "data-score.html#within-subjects-anova",
    "title": "\n5Â  Data Scoring\n",
    "section": "Within-Subjects ANOVA",
    "text": "Within-Subjects ANOVA\nCondition is a within-subject variable in this sample data. Whether you want this variable in long or wide format depends on whether you will use R or JASP to analyze the data.\n\nFor R, you can keep it in long format\nFor JASP, you will need to restructure it to wide format\n\n\n\nCode\nData Frame\n\n\n\n\n# set criterion in setup section of script\nrt_short_criterion &lt;- 200\nrt_long_criterion &lt;- 5000\n\ndata_scores &lt;- data_import |&gt;\n  filter(RT &gt;= rt_short_criterion, RT &lt;= rt_long_criterion) |&gt;\n  summarise(.by = c(ID, Condition),\n            Accuracy.mean = mean(Accuracy, na.rm = TRUE),\n            RT.mean = mean(RT, na.rm = TRUE),\n            RT.sd = sd(RT, na.rm = TRUE)) |&gt;\n  pivot_wider(id_cols = ID,\n              names_from = Condition,\n              values_from = c(Accuracy.mean, RT.mean, RT.sd),\n              names_glue = \"{Condition}_{.value}\")\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#correlation-and-regression",
    "href": "data-score.html#correlation-and-regression",
    "title": "\n5Â  Data Scoring\n",
    "section": "Correlation and Regression",
    "text": "Correlation and Regression\nFor correlation and regression you will want to restructure the data to wide format (same as the code above).\nIf you have multiple data files from different measures or tasks, that you eventually want to merge into a single data frame for analysis, it is a good idea to add the measure or task name to the column names. That way when you merge the data you know which column corresponds to which task.\n\n\nCode\nData Frame\n\n\n\n\n# set criterion in setup section of script\nrt_short_criterion &lt;- 200\nrt_long_criterion &lt;- 5000\n\ndata_scores &lt;- data_import |&gt;\n  filter(RT &gt;= rt_short_criterion, RT &lt;= rt_long_criterion) |&gt;\n  summarise(.by = c(ID, Condition),\n            Accuracy.mean = mean(Accuracy, na.rm = TRUE),\n            RT.mean = mean(RT, na.rm = TRUE),\n            RT.sd = sd(RT, na.rm = TRUE)) |&gt;\n  pivot_wider(id_cols = ID,\n              names_from = Condition,\n              values_from = c(Accuracy.mean, RT.mean, RT.sd),\n              names_glue = \"{task}_{Condition}_{.value}\")\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#remove-problematic-subjects",
    "href": "data-score.html#remove-problematic-subjects",
    "title": "\n5Â  Data Scoring\n",
    "section": "Remove Problematic Subjects",
    "text": "Remove Problematic Subjects\nDepending on the task, problematic subjects can be detected in different ways. For this example data we will simply remove subjects that had less than chance performance on congruent trials (were just guessing or did not understand the task).\nTo do so, we will use a custom function created for this purpose, remove_problematic() from our englelab package. ?englelab::remove_problematic\nThe main argument is remove =. This argument takes a logical statement (e.g., remove = Accuracy.mean &lt;= .5).\nThe other argument, that is more optional, is log_file =. This allows us to save a data file containing only the subjects that were removed. This is good if we later on want to report in publications how many subjects were removed.\n\n\nCode\nData Frame\n\n\n\n\n# set criterion in setup section of script\nacc_criterion &lt;- .34\n\ndata_cleaned &lt;- data_scores |&gt;\n  remove_problematic(\n    remove = \"Stroop_congruent_Accuracy.mean &lt;= acc_criterion\",\n    log_file = here(\"data/logs\", paste(task, \"_problematic.csv\", sep = \"\")))\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#remove-outliers",
    "href": "data-score.html#remove-outliers",
    "title": "\n5Â  Data Scoring\n",
    "section": "Remove Outliers",
    "text": "Remove Outliers\nRemove outliers based on their final task scores. A typical way we remove outliers is by setting their score to missing NA if it is 3.5 standard deviations above or below the mean.\nTo do so, we will use a custom function created for this purpose, replace_outliers from our englelab package.\nThere are several arguments that need to be defined. See ?englelab::replace_outliers for a description on this.\nThe fully piped |&gt; code for this entire section looks like:\n\n\nCode\nData Frame\n\n\n\n\n# set criterion in setup section of script\nacc_criterion &lt;- .34\noutlier_criterion &lt;- 3.5\n\ndata_cleaned &lt;- data_scores |&gt;\n  remove_problematic(\n    remove = \"Stroop_congruent_Accuracy.mean &lt;= acc_criterion\",\n    log_file = here(\"data/logs\", paste(task, \"_problematic.csv\", sep = \"\"))) |&gt;\n  replace_outliers(\n    variables = \"Stroop_incongruent_RT.mean\",\n    cutoff = outlier_criterion,\n    with = \"NA\",\n    pass = 1,\n    id = \"ID\",\n    log_file = here(\"data/logs\", paste(task, \"_outliers.csv\", sep = \"\"))) |&gt;\n  filter(!is.na(Stroop_congruent_RT.mean))\n\nProblematic subjects removed: 1\n\n\nOutliers detected (pass = 1): 0\n\n\nNotice that filter(!is.na()) is specified after replace_outliers. This removes any of the outliers from the dataframe.\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#split-half-reliability",
    "href": "data-score.html#split-half-reliability",
    "title": "\n5Â  Data Scoring\n",
    "section": "Split-half reliability",
    "text": "Split-half reliability\nFirst trials need to be split between even and odd trials (or whatever split-half one is using).\n\n\nCode\nData Frame\n\n\n\n\nsplithalf &lt;- reliability |&gt;\n  mutate(.by = ID,\n         Split = ifelse(Trial %% 2, \"odd\", \"even\"))\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns\n\n\n\n  \n\n\n\n\n\n\nThen scores can be re-calculated based on the even/odd splits. Everything that was done to score the data needs to be included, such as trial-level cleaning.\n\n\nCode\nData Frame\n\n\n\n\nsplithalf &lt;- reliability |&gt;\n  mutate(.by = ID,\n         Split = ifelse(Trial %% 2, \"odd\", \"even\")) |&gt;\n  filter(RT &gt;= rt_short_criterion, RT &lt;= rt_long_criterion) |&gt;\n  summarise(.by = c(ID, Condition, Split),\n            RT.mean = mean(RT, na.rm = TRUE)) |&gt;\n  pivot_wider(id_cols = ID,\n              names_from = c(Condition, Split),\n              values_from = RT.mean)\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns\n\n\n\n  \n\n\n\n\n\n\nFinally, spearman-brown corrected split-half reliability can be calculated and added to the data frame\n\n\nCode\nData Frame\n\n\n\n\nsplithalf &lt;- reliability |&gt;\n  mutate(.by = ID,\n         Split = ifelse(Trial %% 2, \"odd\", \"even\")) |&gt;\n  filter(RT &gt;= rt_short_criterion, RT &lt;= rt_long_criterion) |&gt;\n  summarise(.by = c(ID, Condition, Split),\n            RT.mean = mean(RT, na.rm = TRUE)) |&gt;\n  pivot_wider(id_cols = ID,\n              names_from = c(Condition, Split),\n              values_from = RT.mean) |&gt;\n  summarise(r = cor(incongruent_even, incongruent_odd)) |&gt;\n  mutate(r = (2 * r) / (1 + r))\n\ndata_cleaned$Stroop_incongruent_RT.mean_splithalf &lt;- splithalf$r\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score.html#cronbachs-alpha",
    "href": "data-score.html#cronbachs-alpha",
    "title": "\n5Â  Data Scoring\n",
    "section": "Cronbachâ€™s alpha",
    "text": "Cronbachâ€™s alpha\nCronbachâ€™s alpha is easier to calculate because we do not need to re-calculate the scores.\nThe first step is to get the data frame setup such that trial number is spread across columns\n\n\nCode\nData Frame\n\n\n\n\ncronbachalpha &lt;- reliability |&gt;\n  filter(RT &gt;= rt_short_criterion, RT &lt;= rt_long_criterion) |&gt;\n  select(ID, Trial, Accuracy) |&gt;\n  pivot_wider(id_cols = ID,\n              names_from = Trial,\n              values_from = Accuracy)\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns\n\n\n\n  \n\n\n\n\n\n\nThen we can use psych::alpha() to calculate the average correlation between items and save it to the data frame\n\n\nCode\nData Frame\n\n\n\n\ncronbachalpha &lt;- reliability |&gt;\n  select(ID, Trial, Accuracy) |&gt;\n  pivot_wider(id_cols = ID,\n              names_from = Trial,\n              values_from = Accuracy) |&gt;\n  select(-ID) |&gt;\n  alpha()  # from the psych package\n\nSome items ( 1 ) were negatively correlated with the total scale and \nprobably should be reversed.  \nTo do this, run the function again with the 'check.keys=TRUE' option\n\ndata_cleaned$Stroop_incongruent_RT.mean_cronbachalpha &lt;- \n  cronbachalpha$total$std.alpha\n\n\n\nUse the small arrow â–¸ at the end of the column names to see more columns",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data Scoring</span>"
    ]
  },
  {
    "objectID": "data-score-merge.html",
    "href": "data-score-merge.html",
    "title": "\n6Â  Data Scoring - Merge\n",
    "section": "",
    "text": "At this stage of data processing you have created multiple data files containing the task scores, reliabilities, and other variables for each task. The next step is to create a single merged data file containing the primary task scores for each task that you will be performing data analysis on. We can also create data files with the reliabilities, administration times, and a log of the data cleaning steps.\n\nYou can download an R script template to score tidy raw data files:\n\nenglelab::get_template(score_script = TRUE)\n\nSetup\n\n# ---- Setup ------------------\n# packages\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(tidyr)\n\n# directories\nimport_dir &lt;- \"data/scored\"\noutput_dir &lt;- \"data\"\n\n# file names\noutput_scores &lt;- \"TaskScores.csv\"\noutput_reliabilities &lt;- \"Reliabilities.csv\"\noutput_admintimes &lt;- \"AdminTimes.csv\"\noutput_datacleaning &lt;- \"DataCleaning_log.csv\"\n# -----------------------------\n\nImport\nTo import and merge multiple data frames we can use purrr::map() |&gt; purrr:reduce()\n\n# ---- Import Data ------------\nfiles &lt;- list.files(here(import_dir), pattern = \"Scores\", full.names = TRUE)\ndata_import &lt;- files |&gt;\n  map(read_csv) |&gt;\n  reduce(full_join, by = \"Subject\")\n# -----------------------------\n\nTask Scores\n\n# ---- Select Variables -------\ndata_scores &lt;- data_import |&gt;\n  select(Subject) |&gt;\n  filter()\n\n# list of final subjects\nsubjlist &lt;- select(data_scores, Subject)\n# -----------------------------\n\nAt this step, you may also want to filter out subjects that have missing data on specific tasks, or too much missing data across all the tasks.\nI advise creating a final subject list of all subjects that made it to this state of data processing.\nReliabilities\n\n# ---- Reliabilities ----------\ndata_reliabilities &lt;- data_import |&gt;\n  select(contains(\"splithalf\"), contains(\"cronbach_alpha\")) |&gt;\n  drop_na() |&gt;\n  distinct() |&gt;\n  pivot_longer(everything(),\n               names_to = c(\"Task\", \"metric\"),\n               names_pattern = \"(\\\\w+.\\\\w+).(\\\\w+)\",\n               values_to = \"value\") |&gt;\n  pivot_wider(id_col = Task,\n              names_from = metric,\n              values_from = value)\n# -----------------------------\n\nThe code in pivot_longer(names_pattern = \"(\\\\w+.\\\\w+).(\\\\w+)\") follows a specific naming scheme used for column names. Underscores (optional) can be used for task names and column descriptions, but a period (required) is ONLY used to separate the task name / description from the description of the task score type / what the value represents (e.g., RT = reaction time, splithalf = split-half reliability)\nTask_Name_MoreStuff.ScoreType\ne.g., StroopDL_Last4Rev.ResponseDeadline, VAorient_S.k, Antisaccade.ACC\nThis should also be used for reliabilities and admin times:\ne.g., StroopDL_Last4Rev.splithalf, StroopDL.AdminTime\nAdmin Times\n\n# ---- Admin Times ------------\ndata_merge &lt;- data_import |&gt;\n  select(contains(\"AdminTime\")) |&gt;\n  summarise_all(list(mean = mean, sd = sd), na.rm = TRUE) |&gt;\n  pivot_longer(everything(),\n               names_to = c(\"Task\", \"metric\"),\n               names_pattern = \"(\\\\w+.\\\\w+).(\\\\w+)\",\n               values_to = \"value\") |&gt;\n  mutate(value = round(value, 3)) |&gt;\n  pivot_wider(id_col = Task,\n              names_from = metric,\n              names_prefix = \"AdminTime.\",\n              values_from = \"value\")\n# -----------------------------\n\nData Cleaning Log\nThere will be two sets of cleaning logs we need to import\n\nProblematic subjects\nOutliers\n\n\n# ---- Data Cleaning Log ------\n# problematic subjects\ndata_problematic &lt;- list.files(here(\"data/logs\"), \n                                 pattern = \"problematic\", \n                                 full.names = TRUE) %&gt;%\n  map(read_csv) |&gt;\n  map(function(x) {\n    reframe(x, tibble(Task = gsub(\"\\\\..*\", \"\", colnames(select(x, 2))), \n                       Problematic_Removed = nrow(x)))\n  }) |&gt;\n  bind_rows()\n\n# outliers\ndata_outliers &lt;- list.files(here(\"data/logs\"), \n                                 pattern = \"outliers\", \n                                 full.names = TRUE) %&gt;%\n  map(read_csv) |&gt;\n  map(function(x) {\n    reframe(x, tibble(Task = gsub(\"\\\\..*\", \"\", colnames(select(x, 2))),\n                      Outliers_Removed = nrow(x),\n                      Outliers_Passes = max(pull(x, Pass))))\n  }) |&gt;\n  bind_rows()\n\n# merge\ndata_log &lt;- merge(data_problematic, data_outliers, by = \"Task\", all = TRUE)\n# -----------------------------\n\nSave Data\n\n# ---- Save Data --------------\nwrite_csv(data_scores, here(output_dir, output_scores))\nwrite_csv(data_reliabilities, here(output_dir, output_reliabilities))\nwrite_csv(data_reliabilities, here(output_dir, output_admintimes))\nwrite_csv(data_log, here(output_dir, output_datacleaning))\nwrite_csv(subjlist, here(output_dir, \"subjlist_final.csv\"))\n# -----------------------------\n\nrm(list = ls())",
    "crumbs": [
      "Data Processing",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Data Scoring - Merge</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html",
    "href": "data-analysis-anova.html",
    "title": "\n7Â  ANOVA\n",
    "section": "",
    "text": "Setup Quarto Document\nIf you want to follow along, create an R Project (if you donâ€™t have one already for this guide) with at least the following folders\nğŸ“ analyses\nğŸ“ data\nCreate an empty Quarto document for this chapter.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#yaml",
    "href": "data-analysis-anova.html#yaml",
    "title": "\n7Â  ANOVA\n",
    "section": "YAML",
    "text": "YAML\n---\ntitle: \"Document Title\"\nauthor: Your Name\ndate: today\ntheme: default\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    toc: true\n    toc-depth: 1\n    toc-location: left\n    page-layout: full\n    df-print: paged\nexecute:\n  error: true\n  warning: true\nself-contained: true\neditor_options: \n  chunk_output_type: console\neditor: visual\n---",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#headers",
    "href": "data-analysis-anova.html#headers",
    "title": "\n7Â  ANOVA\n",
    "section": "Headers",
    "text": "Headers\n\nCreate a level 1 header for a Setup section to load packages and set some theme options:\n\n# Setup\n\nCreate a tabset with a tab to load packages and another to set a ggplot2 theme\n\nYou can add multiple tabs easily by going to\n\nIn the toolbar: Insert -&gt; Tabsetâ€¦\n\n::: panel-tabset\n## Required Packages\n\n## Plot Theme\n\n:::",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#r-code-chunks",
    "href": "data-analysis-anova.html#r-code-chunks",
    "title": "\n7Â  ANOVA\n",
    "section": "R Code Chunks",
    "text": "R Code Chunks\n\nAdd an R code chunk below the Required Packages header and load the following packages,\n\n\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(afex)\nlibrary(parameters)\nlibrary(effectsize)\nlibrary(modelbased)\nlibrary(sjPlot)\nlibrary(ggeffects)\nlibrary(modeloutput)\n\n\nAdd an R code chunk below the Plot Theme header and set your own ggplot2 theme to automatically be used in the rest of the document.\n\nThis is a custom theme theme_spacious() I use across all of my plots. It might look like there is a lot going on, but it mainly does two things\n\nIncreases the spacing between axis titles and the axis legend (the default ggplot2 spacing bothers me!)\nBolds the title elements in the plot\n\nI use theme_spacious() along with a ggplot2 theme such as theme_linedraw() . Using theme_set() will automatically apply these themes to all ggplot2 plots generated in this document.\n\n\n\n\n\n\nNote\n\n\n\nSee Class 8: Data Visualization in the R Workshop for a thorough tutorial on ggplot2\n\n\n\ntheme_spacious &lt;- function(font.size = 14, bold = TRUE){\n  key.size &lt;- trunc(font.size * .8)\n  if (bold == TRUE) {\n    face.type &lt;- \"bold\"\n  } else {\n    face.type &lt;- \"plain\"\n  }\n\n  theme(text = element_text(size = font.size),\n        axis.title.x = element_text(margin = margin(t = 15, r = 0,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        axis.title.y = element_text(margin = margin(t = 0, r = 15,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        legend.title = element_text(face = face.type),\n        legend.spacing = unit(20, \"pt\"),\n        legend.text = element_text(size = key.size),\n        plot.title = element_text(face = face.type, hjust = .5,\n                                  margin = margin(b = 10)),\n        plot.caption = element_text(hjust = 0, size = key.size,\n                                    margin = margin(t = 20)),\n        strip.background = element_rect(fill = \"white\", color = \"white\"),\n        strip.text = element_text(color = \"black\",\n                                  face = face.type))\n}\n\noutput_theme &lt;- theme_linedraw() + \n  theme_spacious(font.size = 12) + \n  theme(panel.border = element_rect(color = \"gray\"),\n        axis.line.x = element_line(color = \"gray\"),\n        axis.line.y = element_line(color = \"gray\"),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\ntheme_set(output_theme)",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#specify-factor-levels",
    "href": "data-analysis-anova.html#specify-factor-levels",
    "title": "\n7Â  ANOVA\n",
    "section": "Specify Factor Levels",
    "text": "Specify Factor Levels\nWhen dealing with categorical variables for statistical analyses in R, it is usually a good idea to define the order of the categories as this will by default determine which category is treated as the reference (comparison group). More complex contrast codes will not be covered in this guide.\nLetâ€™s set factor levels for Memory Strategy and Presentation Rate\nRemember you can use colnames() to get the columns in a data frame and unique() to evaluate the unique values in a column.\n\nCreate an R code chunk below the Get Data Ready for Models tab header\n\n\nrecall_data &lt;- data_import |&gt;\n  mutate(Memory_Strategy = factor(Memory_Strategy,\n                                    levels = c(\"Rote Repetition\", \n                                               \"Visual Imagery\")),\n         Presentation_Rate = factor(Presentation_Rate,\n                                    levels = c(1, 2, 4)))\n\nFrom here on out you can create your own header and tabsets as you see fit",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#t-test---independent-samples",
    "href": "data-analysis-anova.html#t-test---independent-samples",
    "title": "\n7Â  ANOVA\n",
    "section": "t-test - independent samples",
    "text": "t-test - independent samples\nWe can perform a two-sample t-test for independent samples to compare recall performance for the group of subjects assigned to the rote repetition condition vs.Â those assigned to the visual imagery condition.\n\nt_ms &lt;- t.test(recall_data$Recall_Performance ~\n                 recall_data$Memory_Strategy, \n               var.equal = TRUE)\n\nThe default way to print output from statistical models in R is either by using a summary() function, or simply printing the statistical model object, t_ms , to the console:\n\n\nR output\nTable ouptut\n\n\n\n\nt_ms\n\n\n    Two Sample t-test\n\ndata:  recall_data$Recall_Performance by recall_data$Memory_Strategy\nt = -10.289, df = 268, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Rote Repetition and group Visual Imagery is not equal to 0\n95 percent confidence interval:\n -13.724492  -9.315508\nsample estimates:\nmean in group Rote Repetition  mean in group Visual Imagery \n                     13.70963                      25.22963 \n\n\n\n\nWe can use model_parameters() , from parameters, to get the test statistics and cohens_d(), from effectsize to get the standardized effect size estimates and print a nice looking table using display from the parameters package.\n\nmodel_parameters(t_ms) |&gt;\n  display(align = \"left\")\n\n\nTwo Sample t-test\n\n\n\n\n\n\n\n\n\n\n\nParameter\nGroup\nrecall_data\\(Memory_Strategy = Rote Repetition | recall_data\\)Memory_Strategy = Visual Imagery\nDifference\n95% CI\nt(268)\np\n\n\n\nrecall_data\\(Recall_Performance | recall_data\\)Memory_Strategy\n13.71\n25.23\n-11.52\n(-13.72, -9.32)\n-10.29\n&lt; .001\n\n\n\nAlternative hypothesis: true difference in means between group Rote Repetition and group Visual Imagery is not equal to 0\n\n\n\n\ncohens_d(t_ms) |&gt;\n  display(align = \"left\")\n\n\n\nCohenâ€™s d\n95% CI\n\n\n-1.25\n[-1.51, -0.99]\n\n\nEstimated using pooled SD.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#t-test---dependent-samples",
    "href": "data-analysis-anova.html#t-test---dependent-samples",
    "title": "\n7Â  ANOVA\n",
    "section": "t-test - dependent samples",
    "text": "t-test - dependent samples\nWe can perform a two-sample t-test for dependent samples to compare the three presentation rate conditions because this variable was a within-subject factor.\nTo do so, we need to create three different data frames for each of the pairwise comparisons (there might be a simpler way to do this using a different t-test function). We can use filter() from dplyr to do this.\n\ndata_pr_1v2 &lt;- filter(recall_data, \n                      Presentation_Rate == 1 | Presentation_Rate == 2)\n\ndata_pr_1v4 &lt;- filter(recall_data, \n                      Presentation_Rate == 1 | Presentation_Rate == 4)\n\ndata_pr_2v4 &lt;- filter(recall_data, \n                      Presentation_Rate == 2 | Presentation_Rate == 4)\n\nt_pr_1v2 &lt;- t.test(data_pr_1v2$Recall_Performance ~\n                     data_pr_1v2$Presentation_Rate, \n                   var.equal = TRUE, paired = TRUE)\n\nt_pr_1v4 &lt;- t.test(data_pr_1v4$Recall_Performance ~\n                     data_pr_1v4$Presentation_Rate, \n                   var.equal = TRUE, paired = TRUE)\n\nt_pr_2v4 &lt;- t.test(data_pr_2v4$Recall_Performance ~\n                     data_pr_2v4$Presentation_Rate, \n                   var.equal = TRUE, paired = TRUE)\n\n\n\nR output\nTable ouptut\n\n\n\n\nt_pr_1v2\n\n\n    Paired t-test\n\ndata:  data_pr_1v2$Recall_Performance by data_pr_1v2$Presentation_Rate\nt = -5.9057, df = 89, p-value = 6.302e-08\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -8.143428 -4.043238\nsample estimates:\nmean difference \n      -6.093333 \n\nt_pr_1v4\n\n\n    Paired t-test\n\ndata:  data_pr_1v4$Recall_Performance by data_pr_1v4$Presentation_Rate\nt = -10.278, df = 89, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -13.717908  -9.273203\nsample estimates:\nmean difference \n      -11.49556 \n\nt_pr_2v4\n\n\n    Paired t-test\n\ndata:  data_pr_2v4$Recall_Performance by data_pr_2v4$Presentation_Rate\nt = -4.6944, df = 89, p-value = 9.642e-06\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -7.688817 -3.115628\nsample estimates:\nmean difference \n      -5.402222 \n\n\n\n\nWe can use model_parameters() , from parameters, to get the test statistics and cohens_d(), from modelbased to get the standardized effect size estimates and print a nice looking table using display from the parameters package.\n\nmodel_parameters(t_pr_1v2) |&gt; \n  display(align = \"left\")\n\n\nPaired t-test\n\n\n\n\n\n\n\n\n\nParameter\nGroup\nDifference\nt(89)\np\n95% CI\n\n\ndata_pr_1v2\\(Recall_Performance | data_pr_1v2\\)Presentation_Rate\n-6.09\n-5.91\n&lt; .001\n(-8.14, -4.04)\n\n\n\nAlternative hypothesis: true mean difference is not equal to 0\n\nmodel_parameters(t_pr_1v4) |&gt; \n  display(align = \"left\")\n\n\nPaired t-test\n\n\n\n\n\n\n\n\n\nParameter\nGroup\nDifference\nt(89)\np\n95% CI\n\n\ndata_pr_1v4\\(Recall_Performance | data_pr_1v4\\)Presentation_Rate\n-11.50\n-10.28\n&lt; .001\n(-13.72, -9.27)\n\n\n\nAlternative hypothesis: true mean difference is not equal to 0\n\nmodel_parameters(t_pr_2v4) |&gt; \n  display(align = \"left\")\n\n\nPaired t-test\n\n\n\n\n\n\n\n\n\nParameter\nGroup\nDifference\nt(89)\np\n95% CI\n\n\ndata_pr_2v4\\(Recall_Performance | data_pr_2v4\\)Presentation_Rate\n-5.40\n-4.69\n&lt; .001\n(-7.69, -3.12)\n\n\n\nAlternative hypothesis: true mean difference is not equal to 0\n\n\n\n\ncohens_d(t_pr_1v2) |&gt;\n  display(align = \"left\")\n\n\n\nCohenâ€™s d\n95% CI\n\n\n-0.62\n[-0.85, -0.40]\n\n\n\ncohens_d(t_pr_1v4) |&gt;\n  display(align = \"left\")\n\n\n\nCohenâ€™s d\n95% CI\n\n\n-1.08\n[-1.34, -0.82]\n\n\n\ncohens_d(t_pr_2v4) |&gt;\n  display(align = \"left\")\n\n\n\nCohenâ€™s d\n95% CI\n\n\n-0.49\n[-0.71, -0.27]",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#tables",
    "href": "data-analysis-anova.html#tables",
    "title": "\n7Â  ANOVA\n",
    "section": "Tables",
    "text": "Tables\nView the different tabs to see different output options:\n\n\nR output\neasystats\nmodeloutput\n\n\n\n\nanova_bs\n\nAnova Table (Type 3 tests)\n\nResponse: Recall_Performance\n           Effect    df   MSE          F  ges p.value\n1 Memory_Strategy 1, 88 26.54 112.50 *** .561   &lt;.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\n\n\nYou can use model_parameters() to get an ANOVA table. You should specify type = 3 to get Type III sum of squares. You can also request to obtain omega-squared (or eta-squared) effect size estimate.\n\nmodel_parameters(anova_bs, type = 3, \n                 effectsize_type = \"omega\", \n                 ci = .95) |&gt;\n  display(align = \"left\")\n\n\nANOVA estimation for factorial designs using â€˜afexâ€™\n\n\n\n\n\n\n\n\n\n\n\nParameter\nSum_Squares\ndf\nMean_Square\nF\np\nOmega2\nOmega2 95% CI\n\n\n\n(Intercept)\n34115.98\n1\n34115.98\n1285.35\n&lt; .001\n\n\n\n\nMemory_Strategy\n2985.98\n1\n2985.98\n112.50\n&lt; .001\n0.55\n(0.44, 1.00)\n\n\nResiduals\n2335.71\n88\n26.54\n\n\n\n\n\n\n\nAnova Table (Type 3 tests)\n\n\nYou can use estimate_contrasts(), from modelbased, to get post-hoc comparisons.\n\nestimate_contrasts(anova_bs, \n                   contrast = \"Memory_Strategy\", \n                   p_adjust = \"tukey\") |&gt;\n  display(align = \"left\")\n\n\nMarginal Contrasts Analysis\n\n\n\n\n\n\n\n\n\n\nLevel1\nLevel2\nDifference\n95% CI\nSE\nt(88)\np\n\n\nRote Repetition\nVisual Imagery\n-11.52\n(-13.68, -9.36)\n1.09\n-10.61\n&lt; .001\n\n\nMarginal contrasts estimated at Memory_Strategy p-value adjustment method: Tukey\n\n\n\n\nMy modeloutput package provides a way to display ANOVA tables in output format similar to other statistical software packages like JASP or SPSS. Add anova_tables(contrast = \"Memory_Strategy\") to get a table for post-hoc comparisons.\n\nanova_tables(anova_bs, contrast = \"Memory_Strategy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOVA Table: Recall_Performance\n\n\nTerm\nSS\ndf\nMS\nF\np\nÎ·2\n\nÏ‰2\n\n\n\n\n\n(Intercept)\n34115.983\nâ€‡1.000\n34115.983\n1285.352\n&lt;0.001\n\n\n\n\nMemory_Strategy\nâ€‡2985.984\nâ€‡1.000\nâ€‡2985.984\nâ€‡112.500\n&lt;0.001\n0.561\n0.553\n\n\nResiduals\nâ€‡2335.709\n88.000\nâ€‡â€‡â€‡26.542\n\n\n\n\n\n\n\n\nModel: aov_car(Recall_Performance ~ Memory_Strategy)\n\n\ndf correction: none\n\n\nN = 90\n\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Memory_Strategy\n\n\nLevel 1\nLevel 2\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\nRote Repetition\nVisual Imagery\nâˆ’11.520\nâˆ’13.678Â â€”Â âˆ’9.362\n1.086\n88Â \nâˆ’10.607\n&lt;0.001\nâˆ’1.490\n\n\np-values are uncorrected.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#figures",
    "href": "data-analysis-anova.html#figures",
    "title": "\n7Â  ANOVA\n",
    "section": "Figures",
    "text": "Figures\nView the different tabs to see different output options:\n\n\nsjPlot\nggplot2\nggplot2 + modeloutput\n\n\n\nThe main package in R to create and customize plots is ggplot2. However, there is definitely a bit of a learning curve to ggplot2. Instead, the sjPlot package offers convenient ways to plot the results of statistical analyses using plot_model().\n\nplot_model(anova_bs, type = \"pred\", show.data = TRUE, jitter = TRUE)\n\n$Memory_Strategy\n\n\n\n\n\n\n\n\nplot_model() actually generates a ggplot2 object so you can further modify using ggplot2 code.\n\n\nThe most customizable way to plot model results is using the ggplot2 package.\n\nggplot(recall_data, aes(x = Memory_Strategy, \n                        y = Recall_Performance,\n                        color = Memory_Strategy)) +\n  geom_point(position = position_jitter(width = .1), alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, size = 3) + \n  geom_errorbar(stat = \"summary\", \n                fun.data = mean_cl_normal, width = .1) +\n  labs(x = \"Memory Strategy\", y = \"Recall Performance\") +\n  scale_color_brewer(palette = \"Set1\") +\n  guides(color = \"none\")\n\n\n\n\n\n\n\n\n\nMy modeloutput function has a geom_flat_violin() function to create the cloud part of the raincloud plot. There are some other modifications that have to be made to other elements of the ggplot as well.\n\nggplot(recall_data, aes(x = Memory_Strategy, \n                        y = Recall_Performance,\n                        color = Memory_Strategy, \n                        fill = Memory_Strategy)) +\n  geom_flat_violin(position = position_nudge(x = .1, y = 0),\n                   adjust = 1.5, trim = FALSE, \n                   alpha = .5, colour = NA) +\n  geom_point(aes(as.numeric(Memory_Strategy) - .15), \n             position = position_jitter(width = .05), alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, size = 3) + \n  geom_errorbar(stat = \"summary\", \n                fun.data = mean_cl_normal, width = .1) +\n  labs(x = \"Memory Strategy\", y = \"Recall Performance\") +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  guides(fill = \"none\", color = \"none\")",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#tables-1",
    "href": "data-analysis-anova.html#tables-1",
    "title": "\n7Â  ANOVA\n",
    "section": "Tables",
    "text": "Tables\nView the different tabs to see different output options:\n\n\nR output\neasystats\nmodeloutput\n\n\n\n\nanova_ws\n\nAnova Table (Type 3 tests)\n\nResponse: Recall_Performance\n             Effect           df   MSE         F  ges p.value\n1 Presentation_Rate 1.97, 175.15 55.48 54.53 *** .188   &lt;.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n\n\n\n\nYou can use model_parameters() to get an ANOVA table. You should specify type = 3 to get Type III sum of squares. You can also request to obtain omega-squared (or eta-squared) effect size estimate.\n\nmodel_parameters(anova_ws, type = 3, \n                 effectsize_type = \"omega\", \n                 ci = .95) |&gt;\n  display(align = \"left\")\n\n\nANOVA estimation for factorial designs using â€˜afexâ€™\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nSum_Squares\nSum_Squares_Error\ndf\ndf (error)\nMean_Square\nF\np\nOmega2 (partial)\nOmega2 95% CI\n\n\nPresentation_Rate\n5953.82\n9718.28\n1.97\n175.15\n55.48\n54.53\n&lt; .001\n0.18\n(0.10, 1.00)\n\n\nAnova Table (Type 3 tests)\n\n\nYou can use estimate_contrasts(), from modelbased, to get post-hoc comparisons.\n\nestimate_contrasts(anova_ws, \n                   contrast = \"Presentation_Rate\", \n                   p_adjust = \"bonferroni\") |&gt;\n  display(align = \"left\")\n\n\nMarginal Contrasts Analysis\n\nLevel1\nLevel2\nDifference\n95% CI\nSE\nt(89)\np\n\n\n\nX1\nX2\n-6.09\n( -8.61, -3.58)\n1.03\n-5.91\n&lt; .001\n\n\nX1\nX4\n-11.50\n(-14.22, -8.77)\n1.12\n-10.28\n&lt; .001\n\n\nX2\nX4\n-5.40\n( -8.21, -2.59)\n1.15\n-4.69\n&lt; .001\n\n\n\nMarginal contrasts estimated at Presentation_Rate p-value adjustment method: Bonferroni\n\n\n\n\nMy modeloutput package provides a way to display ANOVA tables in output format similar to other statistical software packages like JASP or SPSS. Add anova_tables(contrast = \"Presentation_Rate\") to get a table for post-hoc comparisons.\n\nanova_tables(anova_ws, contrast = \"Presentation_Rate\")\n\n\n\n\n\n\n\nANOVA Table: Recall_Performance\n\n\nTerm\nSS\nSS Error\ndf\ndf Error\nMS\nMS Error\nF\np\nÎ·p2\n\nÏ‰p2\n\n\n\n\nPresentation_Rate\n5953.815\n9718.278\n1.968\n175.154\n55.484\n1.018\n54.525\n&lt;0.001\n0.380\n0.184\n\n\n\nModel: aov_car(Recall_Performance ~ (Presentation_Rate) + Error(Subject/(Presentation_Rate)))\n\n\ndf correction: Greenhouse-Geisser\n\n\nN = 90\n\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Presentation_Rate\n\n\nLevel 1\nLevel 2\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\n1\n2\nâ€‡âˆ’6.093\nâ€‡âˆ’8.143Â â€”Â âˆ’4.043\n1.032\n89Â \nâ€‡âˆ’5.906\n&lt;0.001\nâˆ’0.562\n\n\n1\n4\nâˆ’11.496\nâˆ’13.718Â â€”Â âˆ’9.273\n1.118\n89Â \nâˆ’10.278\n&lt;0.001\nâˆ’1.060\n\n\n2\n4\nâ€‡âˆ’5.402\nâ€‡âˆ’7.689Â â€”Â âˆ’3.116\n1.151\n89Â \nâ€‡âˆ’4.694\n&lt;0.001\nâˆ’0.498\n\n\n\np-values are uncorrected.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#figures-1",
    "href": "data-analysis-anova.html#figures-1",
    "title": "\n7Â  ANOVA\n",
    "section": "Figures",
    "text": "Figures\nView the different tabs to see different output options:\n\n\nsjPlot\nggplot2\nggplot2 + modeloutput\n\n\n\nThe main package in R to create and customize plots is ggplot2. However, there is definitely a bit of a learning curve to ggplot2. Instead, the sjPlot package offers convenient ways to plot the results of statistical analyses using plot_model().\n\nplot_model(anova_ws, type = \"pred\", show.data = TRUE, jitter = TRUE)\n\n$Presentation_Rate\n\n\n\n\n\n\n\n\nplot_model() actually generates a ggplot2 object so you can further modify using ggplot2 code.\n\n\nThe most customizable way to plot model results is using the ggplot2 package.\n\nggplot(recall_data, aes(x = Presentation_Rate, \n                        y = Recall_Performance)) +\n  geom_point(position = position_jitter(width = .1), alpha = .2) +\n  geom_line(stat = \"summary\", fun = mean, linewidth = 1, group = 1) +\n  geom_point(stat = \"summary\", fun = mean, size = 3) + \n  geom_errorbar(stat = \"summary\", \n                fun.data = mean_cl_normal, width = .1) +\n  labs(x = \"Presentation Rate\", y = \"Recall Performance\")\n\n\n\n\n\n\n\n\n\nMy modeloutput function has a geom_flat_violin() function to create the cloud part of the raincloud plot. There are some other modifications that have to be made to other elements of the ggplot as well.\n\nggplot(recall_data, aes(x = Presentation_Rate, \n                        y = Recall_Performance)) +\n  geom_flat_violin(position = position_nudge(x = .1, y = 0),\n                   adjust = 1.5, trim = FALSE, \n                   alpha = .5, fill = \"gray\", color = NA) +\n  geom_point(aes(as.numeric(Presentation_Rate) - .15), \n             position = position_jitter(width = .05), alpha = .2) +\n  geom_line(stat = \"summary\", fun = mean, linewidth = 1, group = 1) +\n  geom_point(stat = \"summary\", fun = mean, size = 3) + \n  geom_errorbar(stat = \"summary\", \n                fun.data = mean_cl_normal, width = .1) +\n  labs(x = \"Presentation_Rate\", y = \"Recall Performance\")",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#tables-2",
    "href": "data-analysis-anova.html#tables-2",
    "title": "\n7Â  ANOVA\n",
    "section": "Tables",
    "text": "Tables\nView the different tabs to see different output options:\n\n\nR output\neasystats\nmodeloutput\n\n\n\n\nanova_mixed\n\nAnova Table (Type 3 tests)\n\nResponse: Recall_Performance\n                             Effect           df   MSE          F  ges p.value\n1                   Memory_Strategy        1, 88 79.63 112.50 *** .353   &lt;.001\n2                 Presentation_Rate 1.95, 171.62 55.04  55.47 *** .266   &lt;.001\n3 Memory_Strategy:Presentation_Rate 1.95, 171.62 55.04     2.54 + .016    .083\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n\n\n\n\nYou can use model_parameters() to get an ANOVA table. You should specify type = 3 to get Type III sum of squares. You can also request to obtain omega-squared (or eta-squared) effect size estimate.\n\nmodel_parameters(anova_mixed, type = 3, \n                 effectsize_type = \"omega\", \n                 ci = .95) |&gt;\n  display(align = \"left\")\n\n\nANOVA estimation for factorial designs using â€˜afexâ€™\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nSum_Squares\nSum_Squares_Error\ndf\ndf (error)\nMean_Square\nF\np\nOmega2 (partial)\nOmega2 95% CI\n\n\n\nMemory_Strategy\n8957.95\n7007.13\n1.00\n88.00\n79.63\n112.50\n&lt; .001\n0.55\n(0.44, 1.00)\n\n\nPresentation_Rate\n5953.82\n9445.49\n1.95\n171.62\n55.04\n55.47\n&lt; .001\n0.26\n(0.17, 1.00)\n\n\nMemory_Strategy:Presentation_Rate\n272.79\n9445.49\n1.95\n171.62\n55.04\n2.54\n0.083\n9.85e-03\n(0.00, 1.00)\n\n\n\nAnova Table (Type 3 tests)\n\n\nYou can use estimate_contrasts(), from modelbased, to get post-hoc comparisons.\n\nestimate_contrasts(anova_mixed, \n                   contrast = \"Presentation_Rate\", \n                   at = \"Memory_Strategy\",\n                   p_adjust = \"bonferroni\") |&gt;\n  display(align = \"left\")\n\n\nMarginal Contrasts Analysis\n\n\n\n\n\n\n\n\n\n\n\nLevel1\nLevel2\nMemory_Strategy\nDifference\n95% CI\nSE\nt(88)\np\n\n\n\nX1\nX2\nRote Repetition\n-8.50\n(-11.97, -5.03)\n1.42\n-5.98\n&lt; .001\n\n\nX1\nX2\nVisual Imagery\n-3.69\n( -7.16, -0.22)\n1.42\n-2.59\n0.033\n\n\nX1\nX4\nRote Repetition\n-13.15\n(-16.98, -9.31)\n1.57\n-8.37\n&lt; .001\n\n\nX1\nX4\nVisual Imagery\n-9.84\n(-13.68, -6.01)\n1.57\n-6.26\n&lt; .001\n\n\nX2\nX4\nRote Repetition\n-4.65\n( -8.63, -0.66)\n1.63\n-2.85\n0.016\n\n\nX2\nX4\nVisual Imagery\n-6.16\n(-10.14, -2.17)\n1.63\n-3.77\n&lt; .001\n\n\n\nMarginal contrasts estimated at Presentation_Rate p-value adjustment method: Bonferroni\n\n\n\n\nMy modeloutput package provides a way to display ANOVA tables in output format similar to other statistical software packages like JASP or SPSS. Add anova_tables(contrast = \"Presentation_Rate\") to get a table for post-hoc comparisons.\n\nanova_tables(anova_mixed, \n             contrast = c(\"Presentation_Rate\", \"Memory_Strategy\"), \n             at = c(\"Presentation_Rate\", \"Memory_Strategy\"))\n\n\n\n\n\n\n\nANOVA Table: Recall_Performance\n\n\nTerm\nSS\nSS Error\ndf\ndf Error\nMS\nMS Error\nF\np\nÎ·p2\n\nÏ‰p2\n\n\n\n\n\nMemory_Strategy\n8957.952\n7007.126\n1.000\nâ€‡88.000\n79.626\nâ€‡0.708\n112.500\n&lt;0.001\n0.561\n0.553\n\n\nPresentation_Rate\n5953.815\n9445.486\n1.950\n171.619\n55.037\nâ€‡0.992\nâ€‡55.469\n&lt;0.001\n0.387\n0.260\n\n\nMemory_Strategy:Presentation_Rate\nâ€‡272.792\n9445.486\n1.950\n171.619\n55.037\n21.655\nâ€‡â€‡2.541\nâ€‡â€‡â€‡â€‡0.083\n0.028\n0.010\n\n\n\n\nModel: aov_car(Recall_Performance ~ (Presentation_Rate) * (Memory_Strategy) + Error(Subject/(Presentation_Rate)))\n\n\ndf correction: Greenhouse-Geisser\n\n\nN = 90\n\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Presentation_Rate\n\n\nLevel 1\nLevel 2\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\n1\n2\nâ€‡âˆ’6.093\nâ€‡âˆ’8.091Â â€”Â âˆ’4.095\n1.005\n88Â \nâ€‡âˆ’6.061\n&lt;0.001\nâˆ’0.562\n\n\n1\n4\nâˆ’11.496\nâˆ’13.703Â â€”Â âˆ’9.288\n1.111\n88Â \nâˆ’10.348\n&lt;0.001\nâˆ’1.060\n\n\n2\n4\nâ€‡âˆ’5.402\nâ€‡âˆ’7.697Â â€”Â âˆ’3.108\n1.155\n88Â \nâ€‡âˆ’4.679\n&lt;0.001\nâˆ’0.498\n\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Memory_Strategy\n\n\nLevel 1\nLevel 2\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\nRote Repetition\nVisual Imagery\nâˆ’11.520\nâˆ’13.678Â â€”Â âˆ’9.362\n1.086\n88Â \nâˆ’10.607\n&lt;0.001\nâˆ’1.062\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Presentation_Rate x Memory_Strategy\n\n\nLevel 1\nLevel 2\nMemory_Strategy\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\n1\n2\nRote Repetition\nâ€‡âˆ’8.500\nâˆ’11.326Â â€”Â âˆ’5.674â€‡\n1.422\n88Â \nâˆ’5.978\n&lt;0.001\nâˆ’0.784\n\n\n1\n2\nVisual Imagery\nâ€‡âˆ’3.687\nâ€‡âˆ’6.512Â â€”Â âˆ’0.861â€‡\n1.422\n88Â \nâˆ’2.593\nâ€‡â€‡â€‡â€‡0.011\nâˆ’0.340\n\n\n1\n4\nRote Repetition\nâˆ’13.149\nâˆ’16.271Â â€”Â âˆ’10.027\n1.571\n88Â \nâˆ’8.369\n&lt;0.001\nâˆ’1.212\n\n\n1\n4\nVisual Imagery\nâ€‡âˆ’9.842\nâˆ’12.964Â â€”Â âˆ’6.720â€‡\n1.571\n88Â \nâˆ’6.265\n&lt;0.001\nâˆ’0.908\n\n\n2\n4\nRote Repetition\nâ€‡âˆ’4.649\nâ€‡âˆ’7.894Â â€”Â âˆ’1.404â€‡\n1.633\n88Â \nâˆ’2.847\nâ€‡â€‡â€‡â€‡0.005\nâˆ’0.429\n\n\n2\n4\nVisual Imagery\nâ€‡âˆ’6.156\nâ€‡âˆ’9.400Â â€”Â âˆ’2.911â€‡\n1.633\n88Â \nâˆ’3.770\n&lt;0.001\nâˆ’0.568\n\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Memory_Strategy x Presentation_Rate\n\n\nLevel 1\nLevel 2\nPresentation_Rate\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\nRote Repetition\nVisual Imagery\n1\nâˆ’14.227\nâˆ’17.464Â â€”Â âˆ’10.989\n1.629\n88Â \nâˆ’8.732\n&lt;0.001\nâˆ’1.312\n\n\nRote Repetition\nVisual Imagery\n2\nâ€‡âˆ’9.413\nâˆ’12.687Â â€”Â âˆ’6.139â€‡\n1.647\n88Â \nâˆ’5.714\n&lt;0.001\nâˆ’0.868\n\n\nRote Repetition\nVisual Imagery\n4\nâˆ’10.920\nâˆ’14.328Â â€”Â âˆ’7.512â€‡\n1.715\n88Â \nâˆ’6.368\n&lt;0.001\nâˆ’1.007\n\n\n\np-values are uncorrected.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-anova.html#figures-2",
    "href": "data-analysis-anova.html#figures-2",
    "title": "\n7Â  ANOVA\n",
    "section": "Figures",
    "text": "Figures\nView the different tabs to see different output options:\n\n\nsjPlot\nggplot2\nggplot2 + modeloutput\nggeffects + ggplot2\n\n\n\nThe main package in R to create and customize plots is ggplot2. However, there is definitely a bit of a learning curve to ggplot2. Instead, the sjPlot package offers convenient ways to plot the results of statistical analyses using plot_model().\n\nplot_model(anova_mixed, type = \"int\", show.data = TRUE, jitter = TRUE)\n\n\n\n\n\n\n\nplot_model() actually generates a ggplot2 object so you can further modify using ggplot2 code.\n\n\nThe most customizable way to plot model results is using the ggplot2 package.\n\nggplot(recall_data, aes(x = Presentation_Rate, \n                        y = Recall_Performance,\n                        color = Memory_Strategy, \n                        group = Memory_Strategy)) +\n  geom_point(position = position_jitter(width = .1), alpha = .2) +\n  geom_line(stat = \"summary\", fun = mean, linewidth = 1) +\n  geom_point(stat = \"summary\", fun = mean, size = 3) + \n  geom_errorbar(stat = \"summary\",\n                fun.data = mean_cl_normal, width = .1) +\n  labs(x = \"Presentation Rate\", y = \"Recall Performance\") +\n  scale_color_brewer(palette = \"Set1\", name = \"Memory Strategy\")\n\n\n\n\n\n\n\n\n\nMy modeloutput function has a geom_flat_violin() function to create the cloud part of the raincloud plot. There are some other modifications that have to be made to other elements of the ggplot as well.\n\nggplot(recall_data, aes(x = Presentation_Rate, \n                        y = Recall_Performance,\n                        color = Memory_Strategy, \n                        fill = Memory_Strategy)) +\n  geom_flat_violin(aes(fill = Memory_Strategy),\n                   position = position_nudge(x = .1, y = 0),\n                   adjust = 1.5, trim = FALSE, \n                   alpha = .5, colour = NA) +\n  geom_point(aes(as.numeric(Presentation_Rate) - .15), \n             position = position_jitter(width = .05), alpha = .2) +\n  geom_line(aes(group = Memory_Strategy), \n            stat = \"summary\", fun = mean, size = 1) +\n  geom_point(stat = \"summary\", fun = mean, size = 3) + \n  geom_errorbar(stat = \"summary\", \n                fun.data = mean_cl_normal, width = .1) +\n  labs(x = \"Presentation_Rate\", y = \"Recall Performance\") +\n  scale_color_brewer(palette = \"Set1\", name = \"Memory Strategy\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\n\n\n\nmodel_plot &lt;- anova_mixed |&gt;\n  ggemmeans(terms = c(\"Presentation_Rate\",\n                      \"Memory_Strategy\")) |&gt;\n  rename(Presentation_Rate = x, Memory_Strategy = group, \n         Recall_Performance = predicted) |&gt;\n  mutate(Presentation_Rate = str_remove(Presentation_Rate, \"X\"),\n         Memory_Strategy = factor(Memory_Strategy,\n                                    levels = c(\"Rote Repetition\", \n                                               \"Visual Imagery\")))\n\n\n\n\n  \n\n\n\n\nggplot(model_plot, aes(x = Presentation_Rate, \n                       y = Recall_Performance,\n                       color = Memory_Strategy, \n                       group = Memory_Strategy)) +\n  geom_point(data = recall_data,\n             position = position_jitter(width = .1), alpha = .2) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) + \n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .1) +\n  labs(x = \"Presentation Rate\", y = \"Recall Performance\") +\n  scale_color_brewer(palette = \"Set1\", name = \"Memory Strategy\")",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html",
    "href": "data-analysis-regression.html",
    "title": "\n8Â  Regression\n",
    "section": "",
    "text": "Setup Quarto Document\nIf you want to follow along, create an R Project (if you donâ€™t have one already for this guide) with at least the following folders\nğŸ“ analyses\nğŸ“ data\nCreate an empty Quarto document for this chapter.\nAlternatively, download the englelab analysis Quarto template rather than starting from an empty document.\nenglelab::get_template(analysis_script = TRUE)",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html#yaml",
    "href": "data-analysis-regression.html#yaml",
    "title": "\n8Â  Regression\n",
    "section": "YAML",
    "text": "YAML\n---\ntitle: \"Document Title\"\nauthor: Your Name\ndate: today\ntheme: default\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    toc: true\n    toc-depth: 1\n    toc-location: left\n    page-layout: full\n    df-print: paged\nexecute:\n  error: true\n  warning: true\nself-contained: true\neditor_options: \n  chunk_output_type: console\neditor: visual\n---",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html#headers",
    "href": "data-analysis-regression.html#headers",
    "title": "\n8Â  Regression\n",
    "section": "Headers",
    "text": "Headers\n\nCreate a level 1 header for a Setup section to load packages and set some theme options:\n\n# Setup\n\nCreate a tabset with a tab to load packages and another to set a ggplot2 theme\n\nYou can add multiple tabs easily by going to\n\nIn the toolbar: Insert -&gt; Tabsetâ€¦\n\n::: panel-tabset\n## Required Packages\n\n## Plot Theme\n\n:::",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html#r-code-chunks",
    "href": "data-analysis-regression.html#r-code-chunks",
    "title": "\n8Â  Regression\n",
    "section": "R Code Chunks",
    "text": "R Code Chunks\n\nAdd an R code chunk below the Required Packages header and load the following packages,\n\n\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(e1071)\nlibrary(sjPlot)\nlibrary(correlation)\nlibrary(broom)\nlibrary(performance)\nlibrary(parameters)\nlibrary(modeloutput)\nlibrary(ggeffects)\n#library(mediation) we will use as mediation::mediate() instead of loading here\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(semPlot)\nlibrary(semoutput)\n\n\nAdd an R code chunk below the Plot Theme header and set your own ggplot2 theme to automatically be used in the rest of the document.\n\nThis is a custom theme theme_spacious() I use across all of my plots. It might look like there is a lot going on, but it mainly does two things\n\nIncreases the spacing between axis titles and the axis legend (the default ggplot2 spacing bothers me!)\nBolds the title elements in the plot\n\nI use theme_spacious() along with a ggplot2 theme such as theme_linedraw() . Using theme_set() will automatically apply these themes to all ggplot2 plots generated in this document.\nSee Class 8: Data Visualization in the R Workshop for a thorough tutorial on ggplot2\n\ntheme_spacious &lt;- function(font.size = 14, bold = TRUE){\n  key.size &lt;- trunc(font.size * .8)\n  if (bold == TRUE) {\n    face.type &lt;- \"bold\"\n  } else {\n    face.type &lt;- \"plain\"\n  }\n\n  theme(text = element_text(size = font.size),\n        axis.title.x = element_text(margin = margin(t = 15, r = 0,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        axis.title.y = element_text(margin = margin(t = 0, r = 15,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        legend.title = element_text(face = face.type),\n        legend.spacing = unit(20, \"pt\"),\n        legend.text = element_text(size = key.size),\n        plot.title = element_text(face = face.type, hjust = .5,\n                                  margin = margin(b = 10)),\n        plot.caption = element_text(hjust = 0, size = key.size,\n                                    margin = margin(t = 20)),\n        strip.background = element_rect(fill = \"white\", color = \"white\"),\n        strip.text = element_text(color = \"black\",\n                                  face = face.type))\n}\n\noutput_theme &lt;- theme_linedraw() + \n  theme_spacious(font.size = 12) + \n  theme(panel.border = element_rect(color = \"gray\"),\n        axis.line.x = element_line(color = \"gray\"),\n        axis.line.y = element_line(color = \"gray\"),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\ntheme_set(output_theme)",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html#specify-factor-levels",
    "href": "data-analysis-regression.html#specify-factor-levels",
    "title": "\n8Â  Regression\n",
    "section": "Specify Factor Levels",
    "text": "Specify Factor Levels\nNotice that the Type of Chocolate variable is categorical. When dealing with categorical variables for statistical analyses in R, it is usually a good idea to define the order of the categories as this will by default determine which category is treated as the reference (comparison group).\nLetâ€™s set factor levels for Type of Chocolate\nRemember you can use colnames() to get the columns in a data frame and unique() to evaluate the unique values in a column.\n\nCreate an R code chunk below the Get Data Ready for Models tab header\n\n\nhappiness_data &lt;- data_import |&gt;\n  mutate(Type_of_Chocolate = factor(Type_of_Chocolate,\n                                    levels = c(\"White\", \"Milk\",\n                                               \"Dark\", \"Alcohol\")))\n\nFrom here on out you can create your own header and tabsets as you see fit",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html#regression-1",
    "href": "data-analysis-regression.html#regression-1",
    "title": "\n8Â  Regression\n",
    "section": "Regression",
    "text": "Regression\nThe regression method requires multiple regression models because we have two dependent variables in the mode - the mediation and the outcome measure. The mediator acts as both an independent variable and dependent variable in the model. Because regression requires only one dependent variable, we cannot test the full model in one regression model. Instead, we have to test the different pieces of the model one at a time. We also need to perform a test on the indirect effect itself, which will require a separate model.\nIn order to evaluate the standardize coefficients (which is often times most useful), we need to first convert the the variables into z-scores. This is fairly straightforward but does require some extra code. A z-score is standardized score on the scale of standard deviation units and is calculated as:\nz-score = (raw score - mean) / sd\nWe can create new columns representing the z-scores using mutate() from the dplyr package.\n\ndata_mediation &lt;- happiness_data %&gt;%\n  mutate(Happiness_z = \n           (Happiness - mean(Happiness)) / sd(Happiness),\n         Social_Support_z = \n           (Social_Support - mean(Social_Support)) / sd(Social_Support),\n         Emotion_Regulation_z = \n           (Emotion_Regulation - mean(Emotion_Regulation)) / sd(Emotion_Regulation))\n\nThe standard regression model typically involves three regression models and a model testing the indirect effect.\n\nA model with the total effect: dv ~ iv\n\n\n\nreg_total &lt;- lm(Happiness_z ~ Social_Support_z, \n                data = data_mediation)\n\n\nA model with the effect of the predictor on the mediator: m ~ iv\n\n\n\nreg_med &lt;- lm(Emotion_Regulation_z ~ Social_Support_z, \n              data = data_mediation)\n\n\nA model with the direct effect and the effect of the mediator: dv ~ iv + m\n\n\n\nreg_direct &lt;- lm(Happiness_z ~ Emotion_Regulation_z + Social_Support_z, \n                 data = data_mediation)\n\n\nA statistical test of the indirect effect: mediation::mediate()\n\n\n\nmodel_mediation &lt;- mediation::mediate(reg_med, reg_direct,\n                                      treat = \"Social_Support_z\",\n                                      mediator = \"Emotion_Regulation_z\",\n                                      boot = TRUE, sims = 1000, \n                                      boot.ci.type = \"bca\")\n\n\n\neasystats\nmodeloutput\n\n\n\n1. DV ~ IV\n\nglance(reg_total)\n\n\n  \n\n\nmodel_parameters(reg_total, standardize = \"refit\")\n\n\n  \n\n\n\n2. M ~ IV\n\nglance(reg_med)\n\n\n  \n\n\nmodel_parameters(reg_med, standardize = \"refit\")\n\n\n  \n\n\n\n3. DV ~ IV + M\n\nglance(reg_direct)\n\n\n  \n\n\nmodel_parameters(reg_direct, standardize = \"refit\")\n\n\n  \n\n\n\n4. Mediation\n\nmodel_parameters(model_mediation)\n\n\n  \n\n\n\n\n\n\nRegression Tables\n\nregression_tables(reg_total, reg_direct)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Summary: Happiness_z\n\n\nModel\nR2\n\nR2 adj.\nÎ”R2\n\nÎ”F\ndf1\ndf2\np\nBIC\nBF\nP(Model|Data)\n\n\n\n\nH1\n0.187\n0.181\n\n\n\n\n\n413.995\n\n\n\n\nH2\n0.261\n0.251\n0.074\n14.944\n1Â \n149Â \n&lt;0.001\n404.491\n1.16 Ã— 102\n\n0.991\n\n\n\n\nH1: Happiness_z ~ Social_Support_z; N = 152\n\n\nH2: Happiness_z ~ Emotion_Regulation_z + Social_Support_z; N = 152\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOVA Table: Happiness_z\n\n\nModel\nTerm\nSum of Squares\ndf\nMean Square\nF\np\n\n\n\n\nH1\nRegression\nâ€‡28.207\nâ€‡â€‡2Â \n14.103\n34.456\n&lt;0.001\n\n\nH1\nResidual\n122.793\n150Â \nâ€‡0.819\n\n\n\n\nH2\nRegression\nâ€‡15.276\nâ€‡â€‡3Â \nâ€‡5.092\n26.302\n&lt;0.001\n\n\nH2\nResidual\n111.600\n149Â \nâ€‡0.749\n\n\n\n\n\n\nH1: Happiness_z ~ Social_Support_z; N = 152\n\n\nH2: Happiness_z ~ Emotion_Regulation_z + Social_Support_z; N = 152\n\n\n\n\n\n\n\n\n\nRegression Coefficients: Happiness_z\n\n\nModel\nTerm\nUnstandardized\nStandardized\nt\ndf\np\n\n\nb\n95% CI\nÎ²\n95% CI\nSE\n\n\n\n\nH1\n(Intercept)\n0.000\nâˆ’0.145Â â€”Â 0.145\n0.000\nâˆ’0.145Â â€”Â 0.145\n0.073\n0.000\n150Â \nâ€‡â€‡â€‡â€‡1.000\n\n\nH1\nSocial_Support_z\n0.432\nâ€‡0.287Â â€”Â 0.578\n0.432\nâ€‡0.287Â â€”Â 0.578\n0.074\n5.870\n150Â \n&lt;0.001\n\n\nH2\n(Intercept)\n0.000\nâˆ’0.139Â â€”Â 0.139\n0.000\nâˆ’0.139Â â€”Â 0.139\n0.070\n0.000\n149Â \nâ€‡â€‡â€‡â€‡1.000\n\n\nH2\nEmotion_Regulation_z\n0.350\nâ€‡0.171Â â€”Â 0.530\n0.350\nâ€‡0.171Â â€”Â 0.530\n0.091\n3.866\n149Â \n&lt;0.001\n\n\nH2\nSocial_Support_z\n0.212\nâ€‡0.033Â â€”Â 0.391\n0.212\nâ€‡0.033Â â€”Â 0.391\n0.091\n2.335\n149Â \nâ€‡â€‡â€‡â€‡0.021\n\n\n\n\nH1: Happiness_z ~ Social_Support_z; N = 152\n\n\nH2: Happiness_z ~ Emotion_Regulation_z + Social_Support_z; N = 152\n\n\n\n\n\n\n\n\nregression_tables(reg_med)\n\n\n\n\n\n\n\nModel Summary: Emotion_Regulation_z\n\n\nModel\nR2\n\nR2 adj.\nBIC\n\n\n\nH1\n0.396\n0.392\n368.722\n\n\nH1: Emotion_Regulation_z ~ Social_Support_z; N = 152\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOVA Table: Emotion_Regulation_z\n\n\nModel\nTerm\nSum of Squares\ndf\nMean Square\nF\np\n\n\n\n\nH1\nRegression\n59.837\nâ€‡â€‡2Â \n29.918\n98.456\n&lt;0.001\n\n\nH1\nResidual\n91.163\n150Â \nâ€‡0.608\n\n\n\n\n\nH1: Emotion_Regulation_z ~ Social_Support_z; N = 152\n\n\n\n\n\n\n\n\nRegression Coefficients: Emotion_Regulation_z\n\n\nModel\nTerm\nUnstandardized\nStandardized\nt\ndf\np\n\n\nb\n95% CI\nÎ²\n95% CI\nSE\n\n\n\n\nH1\n(Intercept)\n0.000\nâˆ’0.125Â â€”Â 0.125\n0.000\nâˆ’0.125Â â€”Â 0.125\n0.063\n0.000\n150Â \nâ€‡â€‡â€‡â€‡1.000\n\n\nH1\nSocial_Support_z\n0.630\nâ€‡0.504Â â€”Â 0.755\n0.630\nâ€‡0.504Â â€”Â 0.755\n0.063\n9.922\n150Â \n&lt;0.001\n\n\n\nH1: Emotion_Regulation_z ~ Social_Support_z; N = 152\n\n\n\n\n\n\nMediation\n\nmodel_parameters(model_mediation)",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "data-analysis-regression.html#path-analysis",
    "href": "data-analysis-regression.html#path-analysis",
    "title": "\n8Â  Regression\n",
    "section": "Path Analysis",
    "text": "Path Analysis\nThere is a statistical modelling approach called path analysis that does allow for multiple dependent variables in a single model. Here is how to specify a path analysis model using the lavaan package.\nSee the lavaan website for how to conduct mediation in lavaan\nModel\n\nmodel &lt;- \"\n# a path\nEmotion_Regulation ~ a*Social_Support\n\n# b path\nHappiness ~ b*Emotion_Regulation\n\n# c prime path \nHappiness ~ c*Social_Support\n\n# indirect and total effects\nindirect := a*b\ntotal := c + a*b\n\"\n\nfit &lt;- sem(model, data = happiness_data)\n\n\n\nR output\nsemoutput\nsemPlot\n\n\n\n\nsummary(fit, standardized = TRUE)\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           152\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                       Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Emotion_Regulation ~                                                      \n    Socl_Spprt (a)        0.760    0.076    9.988    0.000    0.760    0.629\n  Happiness ~                                                               \n    Emtn_Rgltn (b)        0.582    0.149    3.905    0.000    0.582    0.350\n    Socl_Spprt (c)        0.424    0.180    2.358    0.018    0.424    0.212\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Emotion_Regltn  232.557   26.676    8.718    0.000  232.557    0.604\n   .Happiness       785.537   90.107    8.718    0.000  785.537    0.739\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    indirect          0.442    0.122    3.637    0.000    0.442    0.221\n    total             0.866    0.147    5.909    0.000    0.866    0.432\n\n\n\n\nI also have a package, semoutput for displaying results from lavaan models:\n\nsem_tables(fit)\n\n\n\n\n\n\nModel Significance\n    \n\nN\n      Ï‡2\n\n      df\n      p\n    \n\n\n152Â \n0.000\n0Â \n\n\n\n\n\n\n\n\n\nModel Fit\n    \n\nCFI\n      RMSEA\n      90% CI\n      TLI\n      SRMR\n      AIC\n      BIC\n    \n\n\n1.000\n0.000\n0.000Â â€”Â 0.000\n1.000\n0.000\n2714.271\n2729.391\n\n\n\n\n\n\n\n\nRegression Paths\n    \n\nPredictor\n      DV\n      \n        Standardized\n      \n    \n\nÎ²\n      95% CI\n      sig\n      SE\n      z\n      p\n    \n\n\n\nSocial_Support\nEmotion_Regulation\n0.629\n0.544Â â€”Â 0.715\n***\n0.044\n14.356\nâ€‡â€‡â€‡â€‡0.000\n\n\nEmotion_Regulation\nHappiness\n0.350\n0.181Â â€”Â 0.520\n***\n0.086\nâ€‡4.057\n&lt;0.001\n\n\nSocial_Support\nHappiness\n0.212\n0.039Â â€”Â 0.384\n*\n0.088\nâ€‡2.402\nâ€‡â€‡â€‡â€‡0.016\n\n\na*b\nindirect\n0.221\n0.109Â â€”Â 0.333\n***\n0.057\nâ€‡3.859\n&lt;0.001\n\n\nc+a*b\ntotal\n0.432\n0.309Â â€”Â 0.555\n***\n0.063\nâ€‡6.882\n&lt;0.001\n\n\n\n * p &lt; .05; ** p &lt; .01; *** p &lt; .001\n    \n\n\n\n\n\n\n\nsize &lt;- .65\nsemPaths(fit, whatLabels = \"std\", layout = \"tree2\", \n         rotation = 2, style = \"lisrel\", optimizeLatRes = TRUE, \n         structural = FALSE, layoutSplit = FALSE,\n         intercepts = FALSE, residuals = FALSE, \n         curve = 1, curvature = 3, nCharNodes = 8, \n         sizeLat = 11 * size, sizeMan = 11 * size, sizeMan2 = 4 * size, \n         edge.label.cex = 1.2 * size, \n         edge.color = \"#000000\", edge.label.position = .40)\n\n\n\n\n\n\n\n\n\n\nIt is highly advised to calculate bootstrapped and bias-corrected confidence intervals around the indirect effect:\n\nmonteCarloCI(fit, nRep = 1000, standardized = TRUE)",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "update-packages.html",
    "href": "update-packages.html",
    "title": "Update Packages",
    "section": "",
    "text": "I will sporadically update my GitHub R Packages. It is recommended to use the latest versions. Copy and paste this code into a script to update the packages on your computer.\n\nlibrary(devtools)\n\ninstall_github(\"EngleLab/englelab\", upgrade = FALSE)\ninstall_github(\"dr-JT/psyworkflow\", upgrade = FALSE)\ninstall_github(\"dr-JT/semoutput\", upgrade = FALSE)\ninstall_github(\"dr-JT/pupillometry\", upgrade = FALSE)\ninstall_github(\"dr-JT/modeloutput\", upgrade = FALSE)",
    "crumbs": [
      "Appendices",
      "Update Packages"
    ]
  }
]